[
  {
    "objectID": "wrangling.html",
    "href": "wrangling.html",
    "title": "Wrangling",
    "section": "",
    "text": "import polars as pl\nimport polars.selectors as cs\nfrom plotnine import *\nfrom great_tables import GT\ntheme_set(theme_linedraw())"
  },
  {
    "objectID": "wrangling.html#data",
    "href": "wrangling.html#data",
    "title": "Wrangling",
    "section": "",
    "text": "import polars as pl\nimport polars.selectors as cs\nfrom plotnine import *\nfrom great_tables import GT\ntheme_set(theme_linedraw())"
  },
  {
    "objectID": "wrangling.html#data-overview",
    "href": "wrangling.html#data-overview",
    "title": "Wrangling",
    "section": "Data Overview",
    "text": "Data Overview\nPolars data frames can be conveniently previewed with\n\nhhap_deaths\n\n\nshape: (10_800, 6)\n\n\n\nregion\ncountry_code\ncountry\nyear\ncause_of_death\ndeaths\n\n\nstr\nstr\nstr\ni64\nstr\nf64\n\n\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"All causes\"\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Acute lower respiratory infect…\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Trachea, bronchus, lung cancer…\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Ischaemic heart disease\"\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Stroke\"\n0.0\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Americas\"\n\"BOL\"\n\"Bolivia (Plurinational State o…\n2019\n\"Trachea, bronchus, lung cancer…\n98.72\n\n\n\"Africa\"\n\"GNB\"\n\"Guinea-Bissau\"\n2019\n\"Chronic obstructive pulmonary …\n98.88\n\n\n\"Africa\"\n\"CIV\"\n\"Cote d'Ivoire\"\n2019\n\"Chronic obstructive pulmonary …\n990.6\n\n\n\"Europe\"\n\"TUR\"\n\"Türkiye\"\n2019\n\"Chronic obstructive pulmonary …\n997.6\n\n\n\"Europe\"\n\"UZB\"\n\"Uzbekistan\"\n2019\n\"All causes\"\n9982.0\n\n\n\n\n\n\nBy default this shows 5 first and 5 last rows of the data. Rows are often called observations or records and columns are called variables or features. If you want to see a few more observations off the top of the dataset, you can call\n\n(hhap_deaths\n    .head(10))\n\n\nshape: (10, 6)\n\n\n\nregion\ncountry_code\ncountry\nyear\ncause_of_death\ndeaths\n\n\nstr\nstr\nstr\ni64\nstr\nf64\n\n\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"All causes\"\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Acute lower respiratory infect…\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Trachea, bronchus, lung cancer…\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Ischaemic heart disease\"\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Stroke\"\n0.0\n\n\n\"Americas\"\n\"ATG\"\n\"Antigua and Barbuda\"\n2010\n\"Chronic obstructive pulmonary …\n0.0\n\n\n\"Western Pacific\"\n\"AUS\"\n\"Australia\"\n2010\n\"All causes\"\n0.0\n\n\n\"Western Pacific\"\n\"AUS\"\n\"Australia\"\n2010\n\"Acute lower respiratory infect…\n0.0\n\n\n\"Western Pacific\"\n\"AUS\"\n\"Australia\"\n2010\n\"Trachea, bronchus, lung cancer…\n0.0\n\n\n\"Western Pacific\"\n\"AUS\"\n\"Australia\"\n2010\n\"Ischaemic heart disease\"\n0.0\n\n\n\n\n\n\nWhen the number of columns is large, this may not be the most convenient way of getting an overview of the data. Alternative representation can be produced using glimpse, which shows the same data in horizontal (textual) form, i.e. every variable now occupies one row.\n\n(clean_fuels\n    .glimpse())\n\nRows: 6402\nColumns: 6\n$ region                       &lt;str&gt; 'Africa', 'Western Pacific', 'Western Pacific', 'Western Pacific', 'Western Pacific', 'Africa', 'Western Pacific', 'Africa', 'Western Pacific', 'Western Pacific'\n$ country_code                 &lt;str&gt; 'SSD', 'NIU', 'TKL', 'COK', 'PLW', 'STP', 'FSM', 'BDI', 'NRU', 'TUV'\n$ country                      &lt;str&gt; 'South Sudan', 'Niue', 'Tokelau', 'Cook Islands', 'Palau', 'Sao Tome and Principe', 'Micronesia (Federated States of)', 'Burundi', 'Nauru', 'Tuvalu'\n$ year                         &lt;i64&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022\n$ pop_clean_fuels_cooking_mln  &lt;f64&gt; 0.0, 0.002, 0.0004, 0.013, 0.007, 0.009, 0.014, 0.013, 0.011, 0.009\n$ prop_clean_fuels_cooking_pct &lt;f64&gt; 0.0, 98.5, 28.3, 72.7, 29.45, 4.1, 13.2, 0.1, 100.0, 75.2\n\n\n\nWe can also look at the table of statistical summaries for our data\n\n(clean_fuels\n    .describe())\n\n\nshape: (9, 7)\n\n\n\nstatistic\nregion\ncountry_code\ncountry\nyear\npop_clean_fuels_cooking_mln\nprop_clean_fuels_cooking_pct\n\n\nstr\nstr\nstr\nstr\nf64\nf64\nf64\n\n\n\n\n\"count\"\n\"6402\"\n\"6402\"\n\"6402\"\n6402.0\n6402.0\n6402.0\n\n\n\"null_count\"\n\"0\"\n\"0\"\n\"0\"\n0.0\n0.0\n0.0\n\n\n\"mean\"\nnull\nnull\nnull\n2006.0\n19.29797\n61.080069\n\n\n\"std\"\nnull\nnull\nnull\n9.522648\n73.100935\n39.952764\n\n\n\"min\"\n\"Africa\"\n\"AFG\"\n\"Afghanistan\"\n1990.0\n0.0\n0.0\n\n\n\"25%\"\nnull\nnull\nnull\n1998.0\n0.23\n16.6\n\n\n\"50%\"\nnull\nnull\nnull\n2006.0\n2.24\n78.0\n\n\n\"75%\"\nnull\nnull\nnull\n2014.0\n10.24\n100.0\n\n\n\"max\"\n\"Western Pacific\"\n\"ZWE\"\n\"Zimbabwe\"\n2022.0\n1257.0\n100.0"
  },
  {
    "objectID": "wrangling.html#filter",
    "href": "wrangling.html#filter",
    "title": "Wrangling",
    "section": "Filter",
    "text": "Filter\nExpressions show up really handy when we need to perform some operations. Logical operation are perhaps among the simplest operations one can think of. For example, we can compare every value in the column region with the string “Europe” and, if there’s a match, return True, otherwise return False. If we now use this vector of logical values as the filter, all the records for which the value True is returned by this operation, will be included in the filtered dataset.\nHere’s the subset of our original clean fuels data for Europe.\n\n# large countries\n(clean_fuels\n    .filter(pl.col(\"region\")==\"Europe\")\n)\n\n\nshape: (1_749, 6)\n\n\n\nregion\ncountry_code\ncountry\nyear\npop_clean_fuels_cooking_mln\nprop_clean_fuels_cooking_pct\n\n\nstr\nstr\nstr\ni64\nf64\nf64\n\n\n\n\n\"Europe\"\n\"SMR\"\n\"San Marino\"\n2022\n0.034\n100.0\n\n\n\"Europe\"\n\"MCO\"\n\"Monaco\"\n2022\n0.04\n100.0\n\n\n\"Europe\"\n\"FRO\"\n\"Faroe Islands\"\n2022\n0.05\n100.0\n\n\n\"Europe\"\n\"AND\"\n\"Andorra\"\n2022\n0.077\n100.0\n\n\n\"Europe\"\n\"ISL\"\n\"Iceland\"\n2022\n0.35\n100.0\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Europe\"\n\"BLR\"\n\"Belarus\"\n1990\n7.48\n73.2\n\n\n\"Europe\"\n\"AUT\"\n\"Austria\"\n1990\n7.72\n100.0\n\n\n\"Europe\"\n\"DEU\"\n\"Germany\"\n1990\n79.12\n100.0\n\n\n\"Europe\"\n\"SWE\"\n\"Sweden\"\n1990\n8.57\n100.0\n\n\n\"Europe\"\n\"PRT\"\n\"Portugal\"\n1990\n9.95\n100.0\n\n\n\n\n\n\nYou can subset the data further by adding more expressions. Let’s for example see if in the modern times there are still countries in Europe where the majority of people lack access to clean fuel for cooking.\n\n(clean_fuels\n    .filter(\n        pl.col(\"region\")==\"Europe\",\n        pl.col(\"year\")==2022,\n        pl.col(\"prop_clean_fuels_cooking_pct\")&lt;50\n        )\n)\n\n\nshape: (1, 6)\n\n\n\nregion\ncountry_code\ncountry\nyear\npop_clean_fuels_cooking_mln\nprop_clean_fuels_cooking_pct\n\n\nstr\nstr\nstr\ni64\nf64\nf64\n\n\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n2022\n1.43\n41.1\n\n\n\n\n\n\nOh, wow! Over half of population of Bosnia still does not have access to clearn fuels for cooking. Lets zoom in on Bosnia and try to visualize the data.\n\n(\nclean_fuels\n    .filter(pl.col(\"country_code\")==\"BIH\")\n)\n\n\nshape: (33, 6)\n\n\n\nregion\ncountry_code\ncountry\nyear\npop_clean_fuels_cooking_mln\nprop_clean_fuels_cooking_pct\n\n\nstr\nstr\nstr\ni64\nf64\nf64\n\n\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n2022\n1.43\n41.1\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n2021\n1.43\n40.9\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n2020\n1.43\n40.85\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n2019\n1.47\n42.05\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n2018\n1.43\n40.8\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n1994\n2.29\n58.0\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n1993\n2.41\n58.9\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n1992\n2.47\n58.25\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n1991\n2.6\n59.5\n\n\n\"Europe\"\n\"BIH\"\n\"Bosnia and Herzegovina\"\n1990\n2.64\n59.2\n\n\n\n\n\n\nWe are interested in how the population with access to clean fuels for cooking has developed over the years, so we place year on x axis and population on y axis.\n\n(\nggplot(&lt;DATA&gt;) +\n    geom_line(mapping=aes(x=\"year\", y=\"pop_clean_fuels_cooking_mln\"))\n)\n\nAs you remember in plotnine the data should go into the first argument of gpplot function. One approach could be to copy the code for subsetting the code for subsetting the clean fuels dataframe into the &lt;DATA&gt; slot inside gpplot function\n\n(\nggplot(\n    clean_fuels\n        .filter(pl.col(\"country_code\")==\"BIH\")\n    ) +\n    geom_line(mapping=aes(x=\"year\", y=\"prop_clean_fuels_cooking_pct\"))\n)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self)\n    137 \n    138         This method will always be called when a ggplot object is the\n    139         last in the cell.\n    140         \"\"\"\n--&gt; 141         self._display()\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self)\n    177             save_format = \"png\"\n    178 \n    179         figure_size_px = self.theme._figure_size_px\n    180         buf = BytesIO()\n--&gt; 181         self.save(buf, format=save_format, verbose=False)\n    182         display_func = get_display_function(format, figure_size_px)\n    183         display_func(buf.getvalue())\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self, filename, format, path, width, height, units, dpi, limitsize, verbose, **kwargs)\n    669             If `True`, print the saving information.\n    670         kwargs :\n    671             Additional arguments to pass to matplotlib `savefig()`.\n    672         \"\"\"\n--&gt; 673         sv = self.save_helper(\n    674             filename=filename,\n    675             format=format,\n    676             path=path,\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self, filename, format, path, width, height, units, dpi, limitsize, verbose, **kwargs)\n    617 \n    618         if dpi is not None:\n    619             self.theme = self.theme + theme(dpi=dpi)\n    620 \n--&gt; 621         figure = self.draw(show=False)\n    622         return mpl_save_view(figure, fig_kwargs)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self, show)\n    274         # ggplot object. Do the copy here as we may/may not\n    275         # assign a default theme\n    276         self = deepcopy(self)\n    277         with plot_context(self, show=show):\n--&gt; 278             self._build()\n    279 \n    280             # setup\n    281             self.figure, self.axs = self.facet.setup(self)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self)\n    356         layers.update_labels(self)\n    357 \n    358         # Give each layer a copy of the data, the mappings and\n    359         # the execution environment\n--&gt; 360         layers.setup(self)\n    361 \n    362         # Initialise panels, add extra data for margins & missing\n    363         # facetting variables, and add on a PANEL variable to data\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/layer.py in ?(self, plot)\n    441     def setup(self, plot: ggplot):\n    442         for l in self:\n--&gt; 443             l.setup(plot)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/layer.py in ?(self, plot)\n    159         Prepare layer for the plot building\n    160 \n    161         Give the layer access to the data, mapping and environment\n    162         \"\"\"\n--&gt; 163         self._make_layer_data(plot.data)\n    164         self._make_layer_mapping(plot.mapping)\n    165         self._make_layer_environments(plot.environment)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/layer.py in ?(self, plot_data)\n    175         \"\"\"\n    176         if plot_data is None:\n    177             data = pd.DataFrame()\n    178         elif hasattr(plot_data, \"to_pandas\"):\n--&gt; 179             data = cast(\"DataFrameConvertible\", plot_data).to_pandas()\n    180         else:\n    181             data = cast(\"pd.DataFrame\", plot_data)\n    182 \n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/polars/dataframe/frame.py in ?(self, use_pyarrow_extension_array, **kwargs)\n   2408             return self._to_pandas_with_object_columns(\n   2409                 use_pyarrow_extension_array=use_pyarrow_extension_array, **kwargs\n   2410             )\n   2411 \n-&gt; 2412         return self._to_pandas_without_object_columns(\n   2413             self, use_pyarrow_extension_array=use_pyarrow_extension_array, **kwargs\n   2414         )\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/polars/dataframe/frame.py in ?(self, df, use_pyarrow_extension_array, **kwargs)\n   2459     ) -&gt; pd.DataFrame:\n   2460         if not df.width:  # Empty dataframe, cannot infer schema from batches\n   2461             return pd.DataFrame()\n   2462 \n-&gt; 2463         record_batches = df._df.to_pandas()\n   2464         tbl = pa.Table.from_batches(record_batches)\n   2465         if use_pyarrow_extension_array:\n   2466             return tbl.to_pandas(\n\nModuleNotFoundError: No module named 'pyarrow'\n\n\n\n&lt;plotnine.ggplot.ggplot at 0x7805ecdf5450&gt;\n\n\nThis code works, but it is somewhat less clear whats going on. A cleaner alternative is by using .pipe() which passess the polars dataframe into the function provided as an argument. In this case our data about bosnian households will be passed as a first argument into the ggplot function, which is what we wanted all along. All code after .pipe(ggplot) is plotnine code, hence the use of +\n\n(clean_fuels\n    .filter(pl.col(\"country_code\")==\"BIH\")\n    .pipe(ggplot) +\n    geom_line(mapping=aes(x=\"year\", y=\"pop_clean_fuels_cooking_mln\"))\n)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self)\n    137 \n    138         This method will always be called when a ggplot object is the\n    139         last in the cell.\n    140         \"\"\"\n--&gt; 141         self._display()\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self)\n    177             save_format = \"png\"\n    178 \n    179         figure_size_px = self.theme._figure_size_px\n    180         buf = BytesIO()\n--&gt; 181         self.save(buf, format=save_format, verbose=False)\n    182         display_func = get_display_function(format, figure_size_px)\n    183         display_func(buf.getvalue())\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self, filename, format, path, width, height, units, dpi, limitsize, verbose, **kwargs)\n    669             If `True`, print the saving information.\n    670         kwargs :\n    671             Additional arguments to pass to matplotlib `savefig()`.\n    672         \"\"\"\n--&gt; 673         sv = self.save_helper(\n    674             filename=filename,\n    675             format=format,\n    676             path=path,\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self, filename, format, path, width, height, units, dpi, limitsize, verbose, **kwargs)\n    617 \n    618         if dpi is not None:\n    619             self.theme = self.theme + theme(dpi=dpi)\n    620 \n--&gt; 621         figure = self.draw(show=False)\n    622         return mpl_save_view(figure, fig_kwargs)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self, show)\n    274         # ggplot object. Do the copy here as we may/may not\n    275         # assign a default theme\n    276         self = deepcopy(self)\n    277         with plot_context(self, show=show):\n--&gt; 278             self._build()\n    279 \n    280             # setup\n    281             self.figure, self.axs = self.facet.setup(self)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/ggplot.py in ?(self)\n    356         layers.update_labels(self)\n    357 \n    358         # Give each layer a copy of the data, the mappings and\n    359         # the execution environment\n--&gt; 360         layers.setup(self)\n    361 \n    362         # Initialise panels, add extra data for margins & missing\n    363         # facetting variables, and add on a PANEL variable to data\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/layer.py in ?(self, plot)\n    441     def setup(self, plot: ggplot):\n    442         for l in self:\n--&gt; 443             l.setup(plot)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/layer.py in ?(self, plot)\n    159         Prepare layer for the plot building\n    160 \n    161         Give the layer access to the data, mapping and environment\n    162         \"\"\"\n--&gt; 163         self._make_layer_data(plot.data)\n    164         self._make_layer_mapping(plot.mapping)\n    165         self._make_layer_environments(plot.environment)\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/plotnine/layer.py in ?(self, plot_data)\n    175         \"\"\"\n    176         if plot_data is None:\n    177             data = pd.DataFrame()\n    178         elif hasattr(plot_data, \"to_pandas\"):\n--&gt; 179             data = cast(\"DataFrameConvertible\", plot_data).to_pandas()\n    180         else:\n    181             data = cast(\"pd.DataFrame\", plot_data)\n    182 \n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/polars/dataframe/frame.py in ?(self, use_pyarrow_extension_array, **kwargs)\n   2408             return self._to_pandas_with_object_columns(\n   2409                 use_pyarrow_extension_array=use_pyarrow_extension_array, **kwargs\n   2410             )\n   2411 \n-&gt; 2412         return self._to_pandas_without_object_columns(\n   2413             self, use_pyarrow_extension_array=use_pyarrow_extension_array, **kwargs\n   2414         )\n\n~/Projects/DATA24WEB/.venv/lib/python3.10/site-packages/polars/dataframe/frame.py in ?(self, df, use_pyarrow_extension_array, **kwargs)\n   2459     ) -&gt; pd.DataFrame:\n   2460         if not df.width:  # Empty dataframe, cannot infer schema from batches\n   2461             return pd.DataFrame()\n   2462 \n-&gt; 2463         record_batches = df._df.to_pandas()\n   2464         tbl = pa.Table.from_batches(record_batches)\n   2465         if use_pyarrow_extension_array:\n   2466             return tbl.to_pandas(\n\nModuleNotFoundError: No module named 'pyarrow'\n\n\n\n&lt;plotnine.ggplot.ggplot at 0x7805a757e7d0&gt;\n\n\n\n# str.contains, str.starts_with, str.ends_with, str.extract, .str.replace, .str.replace_all"
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "Welcome to the lesson on data visualization!\nData visualization is one of the most important skills in data analysis. Why? Because a well-made chart can reveal patterns, trends, and insights that might otherwise stay hidden in a spreadsheet. It’s like turning a jumble of numbers into a picture that tells a story.\nBut let’s be honest—visualizing data can sometimes feel overwhelming. There are so many types of charts to choose from and endless options for customizing them. Scatter plots, bar graphs, heatmaps—what should you use? And even after you pick a plot, there are all these parameters: axis, labels, color scales, gridlines… It’s easy to feel like you’re drowning in options!\nPoint-and-click tools for visualization, like those built into some software, can be helpful, but they come with their own challenges. They often overwhelm you with choices, and worse, they don’t always give you an easy way to reproduce or share your work.\nWhen you create visualizations using a script instead of a mouse, you unlock an entirely new level of power. Scripting your plots means they’re reproducible. You can tweak them, reuse them, and share the code with others. It’s like building a recipe that others can follow, modify, or inspect to understand exactly how the visualization was made.\nNow, let’s take a step back into history for a moment. In 1999, a statistician named Leland Wilkinson published a groundbreaking book called The Grammar of Graphics. Think of it like this: Just as grammar gives structure to language, Wilkinson’s framework gave structure to statistical graphics. He introduced a way to think about and construct plots systematically, rather than relying on intuition or tradition alone.\nHis ideas were revolutionary and influenced countless tools for making visualizations. One of the most famous examples is the R package ggplot2, created by Hadley Wickham. Wickham built on Wilkinson’s Grammar of Graphics and created what is now considered one of the most powerful and popular visualization tools in the world of data science.\nIn 2017 a passionate Python developer from Uganda by the name Hassan Kibridge ported ggplot2 into Python. His project became known as plotnine and it soon became a universal success. Here’s the story of plotnine in his own words:\n\nI discovered this “Grammar of Graphics” thing and found it elegant and powerful. So, I wanted to be able to use it in Python, my preferred programming language for data analysis. I read the key text on the subject by Leland Wilkinson and while I had a good grasp of it, translating it into a usable system would have been a huge undertaking. Hadley Wickham had done so for his doctorate and came up with ggplot2. While I was not confident enough to take this on, I felt that it was quite revolutionary and someone was going to implement it for Python.\nAnd it happened—a project came up that allowed people to seemingly make plots in Python using a grammar just like ggplot2. I started using it but soon discovered that it did not implement a grammar, it just faked one, and it broke down when you tried to make more complicated plots. Since this project was open source, I contributed to improving it. Yet to fix what was lacking grew into a complete overhaul, and this endeavor is what became Plotnine. The first release of which came out in July 2017 after about 3 years of on-and-off development.\nTo my surprise, Plotnine has been more successful than I imagined. For it, I have twice received the Google Open Source Peer Bonus Award—a recognition from Google employees towards open source software that is essential to their work. I have helped someone who was working on a COVID-19 vaccine trial solve a small problem they had run into with Plotnine. And, there is a book or two about it.\n\n\n\n\n\n\n\nTip\n\n\n\nHave a look at the full interview here as well as Hassan’s talk at the posit::conf(2023) in Chicago.\n\n\nWhile the syntax of plotnine might feel a bit different from typical Python code, don’t worry—there’s a reason for it! The goal is to keep the grammar intact, and that consistency makes it easy to learn and incredibly flexible to use.\nIn this lesson, we’ll dive into plotnine and explore how it allows you to create clear, beautiful, and insightful visualizations. We’ll guide you step by step so you can quickly become comfortable with its intuitive and expressive syntax.\nSo, join us on this journey into the wonderful world of data visualization. By the end, you’ll be creating plots that don’t just look good but also communicate your data’s story effectively. Let’s get started!"
  },
  {
    "objectID": "visualization.html#welcome",
    "href": "visualization.html#welcome",
    "title": "Visualization",
    "section": "",
    "text": "Welcome to the lesson on data visualization!\nData visualization is one of the most important skills in data analysis. Why? Because a well-made chart can reveal patterns, trends, and insights that might otherwise stay hidden in a spreadsheet. It’s like turning a jumble of numbers into a picture that tells a story.\nBut let’s be honest—visualizing data can sometimes feel overwhelming. There are so many types of charts to choose from and endless options for customizing them. Scatter plots, bar graphs, heatmaps—what should you use? And even after you pick a plot, there are all these parameters: axis, labels, color scales, gridlines… It’s easy to feel like you’re drowning in options!\nPoint-and-click tools for visualization, like those built into some software, can be helpful, but they come with their own challenges. They often overwhelm you with choices, and worse, they don’t always give you an easy way to reproduce or share your work.\nWhen you create visualizations using a script instead of a mouse, you unlock an entirely new level of power. Scripting your plots means they’re reproducible. You can tweak them, reuse them, and share the code with others. It’s like building a recipe that others can follow, modify, or inspect to understand exactly how the visualization was made.\nNow, let’s take a step back into history for a moment. In 1999, a statistician named Leland Wilkinson published a groundbreaking book called The Grammar of Graphics. Think of it like this: Just as grammar gives structure to language, Wilkinson’s framework gave structure to statistical graphics. He introduced a way to think about and construct plots systematically, rather than relying on intuition or tradition alone.\nHis ideas were revolutionary and influenced countless tools for making visualizations. One of the most famous examples is the R package ggplot2, created by Hadley Wickham. Wickham built on Wilkinson’s Grammar of Graphics and created what is now considered one of the most powerful and popular visualization tools in the world of data science.\nIn 2017 a passionate Python developer from Uganda by the name Hassan Kibridge ported ggplot2 into Python. His project became known as plotnine and it soon became a universal success. Here’s the story of plotnine in his own words:\n\nI discovered this “Grammar of Graphics” thing and found it elegant and powerful. So, I wanted to be able to use it in Python, my preferred programming language for data analysis. I read the key text on the subject by Leland Wilkinson and while I had a good grasp of it, translating it into a usable system would have been a huge undertaking. Hadley Wickham had done so for his doctorate and came up with ggplot2. While I was not confident enough to take this on, I felt that it was quite revolutionary and someone was going to implement it for Python.\nAnd it happened—a project came up that allowed people to seemingly make plots in Python using a grammar just like ggplot2. I started using it but soon discovered that it did not implement a grammar, it just faked one, and it broke down when you tried to make more complicated plots. Since this project was open source, I contributed to improving it. Yet to fix what was lacking grew into a complete overhaul, and this endeavor is what became Plotnine. The first release of which came out in July 2017 after about 3 years of on-and-off development.\nTo my surprise, Plotnine has been more successful than I imagined. For it, I have twice received the Google Open Source Peer Bonus Award—a recognition from Google employees towards open source software that is essential to their work. I have helped someone who was working on a COVID-19 vaccine trial solve a small problem they had run into with Plotnine. And, there is a book or two about it.\n\n\n\n\n\n\n\nTip\n\n\n\nHave a look at the full interview here as well as Hassan’s talk at the posit::conf(2023) in Chicago.\n\n\nWhile the syntax of plotnine might feel a bit different from typical Python code, don’t worry—there’s a reason for it! The goal is to keep the grammar intact, and that consistency makes it easy to learn and incredibly flexible to use.\nIn this lesson, we’ll dive into plotnine and explore how it allows you to create clear, beautiful, and insightful visualizations. We’ll guide you step by step so you can quickly become comfortable with its intuitive and expressive syntax.\nSo, join us on this journey into the wonderful world of data visualization. By the end, you’ll be creating plots that don’t just look good but also communicate your data’s story effectively. Let’s get started!"
  },
  {
    "objectID": "visualization.html#libraries",
    "href": "visualization.html#libraries",
    "title": "Visualization",
    "section": "Libraries",
    "text": "Libraries\nBefore we dive in, let’s talk about the tools and libraries we’ll be using in this lesson.\n\nimport polars as pl\nfrom plotnine import *\nfrom gapminder import gapminder\n\nFirst up is polars, the powerful data analysis library we’ll be relying on throughout the course. If you’re familiar with Python, you know it’s common practice to use shorthand or aliases when importing libraries. For polars, the standard alias is pl, so that’s what we’ll use here. Anytime we call a function from polars, it will be prefixed with pl.—simple and consistent.\nNow, when it comes to our visualization library, plotnine, we’ll take a slightly different approach. Instead of using a prefix, we’ll import all its functions directly into our workspace. This means we’ll use the from plotnine import * syntax, which essentially says, “Hey Python, bring in everything from plotnine!” Why? Because it makes our plotting code cleaner, easier to read, and more expressive.\nFinally, let’s talk about the dataset we’ll be exploring today. It comes from the gapminder package. If you’re not familiar with Gapminder, it’s a non-profit organization founded by Hans Rosling and his children back in 2005. Their mission? To promote a better understanding of global development through data—focusing on health, economics, and the environment.\nThe Gapminder Foundation maintains an incredible collection of statistics about the world, and this package is a small extract from their database. It’s packed with fascinating data on public health, economic development, and global welfare.\nHans Rosling himself is famous for his captivating TED Talk in 2007, where he used data to tell the story of global development. He spoke about life expectancy, GDP, and even the humble washing machine—and how it changed the world. If you haven’t watched that talk yet, I can’t recommend it enough. It’s a masterclass in how to make data come alive.\nSo, with our tools in hand and an inspiring dataset at our fingertips, we’re ready to start exploring and visualizing. Let’s get to it!"
  },
  {
    "objectID": "visualization.html#data",
    "href": "visualization.html#data",
    "title": "Visualization",
    "section": "Data",
    "text": "Data\nThe dataset has been conveniently imported for us by the gapminder package. To get started, we can simply type gapminder into our console and hit Enter. When we do that, we’ll see a preview of the data in the form of a table — what we call a DataFrame. In this table, each row represents an observation, and each column represents a variable.\n\ngapminder\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\n0\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.445314\n\n\n1\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.853030\n\n\n2\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.100710\n\n\n3\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.197138\n\n\n4\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.981106\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1699\nZimbabwe\nAfrica\n1987\n62.351\n9216418\n706.157306\n\n\n1700\nZimbabwe\nAfrica\n1992\n60.377\n10704340\n693.420786\n\n\n1701\nZimbabwe\nAfrica\n1997\n46.809\n11404948\n792.449960\n\n\n1702\nZimbabwe\nAfrica\n2002\n39.989\n11926563\n672.038623\n\n\n1703\nZimbabwe\nAfrica\n2007\n43.487\n12311143\n469.709298\n\n\n\n\n1704 rows × 6 columns\n\n\n\nThis dataset has 1,704 rows and 6 columns, so it’s fairly compact but still rich with information. Let’s walk through what each of these columns means:\n\ncountry: This column lists the names of countries. If you take a look at the data, you’ll notice it starts with Afghanistan at the top and ends with Zimbabwe at the bottom. It seems the data is sorted alphabetically by country.\ncontinent: Here, we have the names of continents. For example, Afghanistan is listed under Asia, while Zimbabwe is under Africa. Makes perfect sense.\nyear: This column tells us the year of the observation. You’ll notice that each country has multiple rows because data was collected at different times. The dataset starts in 1952 and progresses in 5-year increments, which gives us a nice snapshot of changes over time.\nlifeExp: This column stands for life expectancy at birth. If we look at Afghanistan in 1952, for example, the life expectancy was just 28.8 years. Let that sink in for a moment — only 28 years! It’s a sobering reminder of the challenges some nations faced in the mid-20th century.\npop: This column shows the population of each country. Again, looking at Afghanistan in 1952, the population was just under 8.5 million people.\ngdpPercap: Finally, this column contains the GDP per capita, expressed in US dollars. From what I understand, these figures have been adjusted for inflation, so they should be comparable across countries and over time.\n\nAltogether, these six columns give us a fascinating lens through which to explore global trends in health, wealth, and population growth. The dataset might look simple at first glance, but it’s packed with stories waiting to be uncovered.\nNow that we know what we’re working with, let’s roll up our sleeves and start exploring!"
  },
  {
    "objectID": "visualization.html#first-plot",
    "href": "visualization.html#first-plot",
    "title": "Visualization",
    "section": "First plot",
    "text": "First plot\nNow, it’s time to create our very first plot! Here is a question we would like to answer using gapminder data:\n\n\n\n\n\n\nQuestion\n\n\n\nDo people in rich countries live longer than people in poor countries?\n\n\nThe answer may be quite intuitive, but we will continue our investigation further\n\n\n\n\n\n\nQuestion\n\n\n\n\nHow does the relationship between GDP per capita and Life expectancy look like? Is this relationship linear? Non-linear?\nAre there exceptions to the general rule (outliers)?\n\n\n\nIn order to answer these questions, we will create a plot from gapminder data. Here’s the code we’ll use. Take a moment to copy this code verbatim from your screen.\nWhen writing Python code with plotnine — and later when we use polars — you’ll notice that we often wrap our code in parentheses. This is a great habit to get into because it allows us to break our code into multiple lines without worrying about indentation.\n\n(\nggplot(gapminder)+\ngeom_point(mapping=aes(x='gdpPercap', y='lifeExp'))\n)\n\n\n\n\n\n\n\n\nLet’s walk through this step by step.\nInside the outer parentheses, the first thing we write is ggplot. This is the foundational function in plotnine, and it stands for Grammar of Graphics plot. Then, in parentheses again, we pass the dataset we want to use — in this case, gapminder.\nAfter that, we add a plus sign. The Grammar of Graphics, which plotnine is built on, thinks of plots as being made up of layers. The + sign we added tells Python that we’re adding more layers or components to our plot. Think of it as saying, “Wait, there’s more!”\nOn the next line, we write geom_point. This is the function that specifies the type of layer we’re adding to our plot. In this case, it’s a point plot, which means we’ll be drawing points on a graph. Without this layer, our plot would just be an empty canvas.\nInside the geom_point parentheses, we specify the argument: mapping followed by an = sign. This tells plotnine how we want to relate our data to the graph. AES stands for “aesthetics”. The inside of the aes function defines mapping of the variables in our data to certain aesthetical properies of our graph. We’re saying, “Take the GDP per capita (gdpPercap) and map it to the x-axis, and take life expectancy (lifeExp) and map it to the y-axis.” Notice that the column names are enclosed in quotes — that’s important!\nOnce you’ve written the code, go ahead and hit the Run button. If everything is correct, you should see your plot appear on the screen.\nLet’s take a moment to reflect on what we just did.\nIn our code, the first layer was the ggplot function, where we provided the dataset. The second layer was geom_point, which added points to our graph.\nThe result is a simple yet meaningful scatter plot. It shows a positive, non-linear relationship between GDP per capita on the x-axis and life expectancy on the y-axis. Does this align with what you initially expected? Or does it challenge your assumptions? Already, you can see how visualizing data helps uncover patterns and stories that might not be obvious at first glance.\nTake your time to review the code and compare it to the plot we created. Understanding this connection — how the code you write translates directly into what you see on the screen — is the key to mastering data visualization.\nIn fact, the structure of most plots in plotnine (and its R counterpart, ggplot2) can be summarized with a simple template:\nggplot(data = &lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;))\nThis template is incredibly flexible and serves as the foundation for almost every visualization we’ll create.\nIn the remainder of this lesson, we’ll explore how to extend and customize this template to create a wide variety of visualizations. Each new element we add will open up even more possibilities.\nI’ll see you in the next one!"
  },
  {
    "objectID": "visualization.html#axis",
    "href": "visualization.html#axis",
    "title": "Visualization",
    "section": "Axis",
    "text": "Axis\nHello again! Ready for a challenge? I’ve got a question for you:\n\n\n\n\n\n\nChallenge\n\n\n\nHow has life expectancy changed over time?\n\n\nTake a moment to think about it. Better yet, try answering it by modifying the code we wrote in the last lesson.\nHere’s a quick hint before you pause the video: The gapminder dataset includes a column called year, which can go on the x-axis. Use that to tweak the code and see what you find. I’ll wait right here while you try it out!\nPause the video now and give it a shot. See you in a moment!\n\n\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='year', y='lifeExp'))\n)\n\n\n\n\n\n\n\n\nDone? Excellent! Let’s take a look at what we’ve got. Nice work! You should see a scatter plot showing life expectancy over time.\nHmm… notice how some of the points are stacked on top of each other? That’s called overplotting, and it’s pretty common when you have a lot of data points at the same x or y values. Don’t worry—it’s easy to fix!\nInstead of geom_point, try using geom_jitter. This will add a tiny bit of random noise to spread out the points so they’re easier to see.\nHere’s how you do it:\n\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='year', y='lifeExp'))\n)\n\n\n\n\n\n\n\n\nRun this code and check out the difference. Much better, right? Now we can see the points more clearly.\nLet’s keep going with this little game. Here’s your next challenge:\n\n\n\n\n\n\nChallenge\n\n\n\nCan you visualize life expectancy by continent?\n\n\nThink about which variable should go on the x-axis this time. Which continent do you think tends to have the highest life expectancy? Modify your code and give it a shot. Pause the video, try it out, and come back when you’re ready.\n\n\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='continent', y='lifeExp'))\n)\n\n\n\n\n\n\n\n\nGreat job! What do we see here? Looks like life expectancy in Oceania is quite high, although there aren’t many points for that region. Europe is a close second. On the other hand, Africa seems to have the lowest life expectancy overall, judging by the density of points at the lower end of the y-axis.\nHere’s another question: Which continent has the widest spread in life expectancy values? That’s right—it’s Asia. There’s quite a bit of variation there, which is something we’ll dig into in more detail later in the course.\nFantastic work so far! Take a moment to review what you’ve done, and I’ll see you in the next section!"
  },
  {
    "objectID": "visualization.html#aestetical-mapping",
    "href": "visualization.html#aestetical-mapping",
    "title": "Visualization",
    "section": "Aestetical mapping",
    "text": "Aestetical mapping\n&lt;…Walks in, looking thoughtful….&gt;\nOh, hey there! You know, I’ve been thinking—what if we could combine the graphs from the last two challenges and show the relationship between not just two variables, but three?\nNow, don’t worry—we’re not diving into “three-dimensional” plots just yet. Instead, we can represent a third variable using color. Let me show you what I mean.\nHere’s modified code that maps the continent variable to the color aesthetic:\n\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='year', y='lifeExp', color='continent'))\n)\n\n\n\n\n\n\n\n\nRun this code and take a look.\n\nWhat do you see? Now we can see more clearly how life expectancy has changed over time by continent. For example, the points representing Africa stay clustered near the lower end of the y-axis throughout the years, while Europe’s points are generally higher. Oceania is there too, but it’s barely noticeable because there are so few observations. Pretty cool, right?\nNow, I’ve got a question for you: What happens if we switch the mappings of continent and year? Give it a try!\n\n\n\n\n\n\nChallenge\n\n\n\nSwitch the mappings of continent and year in this sample code\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='year', y='lifeExp', color='continent'))\n)\n\n\n\n# switch aesthetics\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='continent', y='lifeExp', color='year'))\n)\n\n\n\n\n\n\n\n\n\nDone? Great! Do you still find this graph useful? Why or why not?\nNow let’s tweak it a bit more. What if, instead of mapping color to year, we mapped it to country? Give it a try!\n\n\n\n\n\n\nChallenge\n\n\n\nMap color to country in this sample code:\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='continent', y='lifeExp', color='year'))\n)\n\n\n\n# color by country\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='continent', y='lifeExp', color='country'))\n)\n\n\n\n\n\n\n\n\nWhat changed? How does mapping color to country differ from mapping it to year? Take a moment to think about it. What do you think is the main limitation of using the color aesthetic?\nAlright, here’s one last challenge for this section: Can you add a splash of color to our original graph of life expectancy by GDP per capita? Let’s color the points by continent.\n\n\n\n\n\n\nChallenge\n\n\n\nColor the points by continent in this sample code:\n(\nggplot(gapminder) +\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp'))\n)\n\n\nTake a moment to run your code and see what you get.\n\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp', color='continent'))\n)\n\n\n\n\n\n\n\n\n\nAmazing! By adding color, we can now spot trends and patterns more easily. But did you notice something else? There are a few outliers in this plot. Can you tell which continent those points belong to?\nThe points look a little crowded. But you know, you can always transform GDP per capita to a logarithmic scale for better visualization. Just add scale_x_log10() as an additional layer to your graph, like that:\n\n# transform the scales\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp', color='continent'))+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nYou’re making fantastic progress! Well done! In the next section, we’ll explore even more aesthetics that can help us tell richer stories with our data. See you there!"
  },
  {
    "objectID": "visualization.html#more-aesthetics",
    "href": "visualization.html#more-aesthetics",
    "title": "Visualization",
    "section": "More aesthetics",
    "text": "More aesthetics\nHello again!\nSo far, we’ve explored some powerful ways to visualize data using the x, y, and color aesthetics. With these, we’ve been able to represent three variables in a single plot. Pretty amazing, right?\nNow, let’s quickly recap what we’ve learned about the color aesthetic. When we map a categorical variable like continent to color, plotnine automatically picks a distinct palette for each category. This works great when there are just a few categories, but as the number of categories grows, the colors start to blur together and lose their effectiveness.\nOn the other hand, when we map a continuous variable like year to color, we get a gradient. While individual values can be harder to pinpoint, the overall trends are beautifully highlighted by the gradient’s brightness.\nAlright, as promised, let me introduce you to another fantastic aesthetic: size.\nImagine we could vary the size of the points in our graph to represent something meaningful—like the population of a country. That would let us visualize not three, but four variables at the same time. Let’s give it a shot. Here’s the code:\n\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp', color='continent', size='pop'))+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nWRun this and take a moment to appreciate the result. Isn’t it gorgeous?\nNow we can see the journey of countries like China and India over time. Their points stand out because of their large populations. Under the logarithmic transformation of the x-axis, the relationship between GDP per capita and life expectancy starts to look more linear—but not quite!\nNotice the outliers on the far right? They all seem to be from Asian countries. Are these countries rich or poor? Rich, right? But their life expectancy doesn’t quite follow the trend we see in Europe or the Americas. Fascinating, isn’t it?\nNow, let me share one more aesthetic property with you: shape.\nShape can be a great tool for visualizing low-cardinality categorical variables, like continent. Instead of just using circles, we can use distinct shapes for each category. This lets us pack even more information into the same graph.\nReady for a challenge? Let’s push the limits and visualize five dimensions in a single plot. Modify the previous example to map year to color and continent to shape. Take a moment and try it. I’ll wait.\n\n\n\n\n\n\nChallenge\n\n\n\nMap year to color and continent to shape in this sample code\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp', color='continent', size='pop'))+\nscale_x_log10()\n)\n\n\n\n\n# map year to color and continent to shape\n\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp', color='year', size='pop', shape='continent'))+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nWhat do you notice? Can you tell whether those Asian outliers come from small or large countries? Are they from earlier or later time periods?\nThese are the kinds of questions we can answer when we use multiple aesthetics thoughtfully. Isn’t it amazing how much information we can pack into a single visualization?\nFantastic work today! In the next lesson, we’ll continue exploring new tools and techniques to take your visualizations even further. See you soon!"
  },
  {
    "objectID": "visualization.html#non-data-linked-properties",
    "href": "visualization.html#non-data-linked-properties",
    "title": "Visualization",
    "section": "Non-data linked properties",
    "text": "Non-data linked properties\nWelcome back!\nSo far, we’ve packed a lot of information into single graphs using data-mapped aesthetics like color, size, and shape. While this approach is powerful, let’s face it—combining too many aesthetics can make a plot feel busy and overwhelming.\nSometimes, less is more. A clean and simple graph, highlighting just one or two aspects of the data, can be just as insightful—and a lot easier on the eyes.\nNow, the default style in plotnine is already quite nice, but there may come a time when you want to tweak things to better suit your storytelling. So, let’s look at how to customize graphs using non-data-linked properties—those that aren’t mapped to a variable but instead apply globally to all points in the graph.\nHere’s an example. What if we want all the points in our plot to be the same color, say blue? And what if we also want to adjust their size and transparency? Here’s the code to do that:\n\n(\nggplot(gapminder)+\ngeom_point(mapping = aes(x='gdpPercap', y='lifeExp'),\n            alpha=0.1, size=2, color='blue')\n)\n\n\n\n\n\n\n\n\nGo ahead, give this a try.\n\nBeautiful, isn’t it? All the points are now blue, with a larger size and a soft transparency that makes overlapping points blend together nicely. This transparency, or alpha, helps highlight areas where the data is dense—like shadows on a heatmap.\nNotice something? The color, size, and alpha settings aren’t part of the aes() function. That’s because these properties aren’t mapped to any variable in the data. Instead, they’re applied uniformly to every point in the plot.\nLet’s break it down:\n\ncolor=\"blue\": The color is set as a character string, wrapped in quotes. You can experiment with other colors too—try red, green, or even hex codes like “#FF5733”.\nsize=2: The size of the points is specified as a number, in millimeters. Increase the size to make the points larger or decrease it for smaller ones.\nalpha=0.1: Transparency is a decimal value between 0 and 1, where 0 is completely transparent and 1 is fully opaque.\n\nFinally, let’s talk about shapes. In plotnine, shapes are represented by numbers. For example:\n\n0 is a square,\n1 is a circle,\n2 is a triangle,\n20 is a small filled circle.\n\nHere’s a challenge for you\n\n\n\n\n\n\nChallenge\n\n\n\nChange the shape argument in the code to explore different shapes. Try values between 0 and 25, and see how your graph changes. You’ll find the full list of shapes in the plotnine documentation.\n\n\nSo, what do you think? With just a few tweaks, we’ve turned our scatter plot into a clean and stylish visual. Customizing non-data-linked properties like this is a great way to emphasize certain elements of your data without overwhelming your audience.\nIn the next lesson, we’ll explore even more ways to take your visualizations to the next level. See you there!"
  },
  {
    "objectID": "visualization.html#geometrical-objects",
    "href": "visualization.html#geometrical-objects",
    "title": "Visualization",
    "section": "Geometrical objects",
    "text": "Geometrical objects\nWelcome back! Let’s dive into another exciting aspect of creating visualizations in plotnine: geometrical objects, or geom_ functions.\nThese geom_ functions are the building blocks of your plots, allowing you to highlight different aspects of your data. By swapping or combining geom_ layers, you can tell entirely new stories with the same dataset.\nFor example, what if we wanted to show the development of life expectancy over time for each country? We could use geom_line() to connect individual data points belonging to the same country.\nHere’s the code to do just that:\n\n(\nggplot(gapminder)+\ngeom_line(mapping = aes(x='year', y='lifeExp',\n          group='country', color='continent'))\n)\n\n\n\n\n\n\n\n\nNote that we have a new aesthetics called group. It indicates which points need to be connected together to for a line. Here we are drawing one line per country. Take a moment to run this and see what you get.\n\nDo you see it? Each country now has its own line, colored by continent. It’s fascinating to watch life expectancy trends unfold over time. But look closely—you might notice some sharp, sudden drops for certain countries. What do you think caused these declines? Wars? Epidemics?\nWe’ll learn how to zoom in on these tragic moments and identify the affected countries later in the course, once we’ve mastered some data wrangling with Polars. For now, make a mental note of this question so you can return to it later.\nAnother powerful geometrical object is geom_boxplot(). This creates a “box-and-whisker” plot that illustrates the distribution of values within categories.\nFor example, let’s visualize how life expectancy varies by continent:\n\n(\nggplot(gapminder)+\ngeom_boxplot(mapping = aes(x='continent', y='lifeExp'))\n)\n\n\n\n\n\n\n\n\nRun the code and take a look.\n\nThe box represents the interquartile range—the middle 50% of data—while the line inside the box marks the median. The “whiskers” extend to show the 95% confidence interval, and any points outside this range are plotted as individual outliers.\nNow, wouldn’t it be great to combine this boxplot with our jittered points from earlier? This would help us see both the overall distribution and the outliers more clearly. Let’s layer them together:\n\n(\nggplot(gapminder)+\ngeom_jitter(mapping = aes(x='continent', y='lifeExp', color='continent'))+\ngeom_boxplot(mapping = aes(x='continent', y='lifeExp', color='continent'))\n)\n\n\n\n\n\n\n\n\n\nLooks great, doesn’t it? But notice something—there’s some duplication in our code. We had to repeat the same mappings for both geom_jitter and geom_boxplot. That’s fine for now, but it can become cumbersome as your visualizations grow more complex.\nHere’s a trick to make your code cleaner: you can move shared mappings to the parent ggplot() function. This way, every layer will “inherit” these mappings automatically:\n\n(\nggplot(gapminder, mapping = aes(x='continent', y='lifeExp', color='continent'))+\ngeom_jitter()+\ngeom_boxplot()\n)\n\n\n\n\n\n\n\n\nSee? No more repeating yourself! You can still add layer-specific settings or arguments within individual geom_ functions if needed.\n\n\n\n\n\n\nTip\n\n\n\nWhen building complex plots, start by adding one layer at a time. Once you’ve got the basic structure, move any common arguments up to the ggplot() function. This keeps your code tidy and easier to read.\n\n\nGreat job so far! In the next lesson, we’ll explore even more ways to enhance your visualizations. See you there!"
  },
  {
    "objectID": "visualization.html#trend-lines",
    "href": "visualization.html#trend-lines",
    "title": "Visualization",
    "section": "Trend lines",
    "text": "Trend lines\nWelcome back! Now, let’s take a closer look at the relationship between GDP per capita and life expectancy.\nAt first glance, life expectancy seems to improve as countries get richer. But is this relationship consistent across continents? Let’s find out by adding trend lines to our plot.\nTrends are essentially linear regression lines. You might remember them from school—they represent the best-fit line through your data. Here’s how we can add them to highlight differences in this relationship by continent:\n\n(\nggplot(gapminder, mapping = aes(x='gdpPercap', y='lifeExp', color='continent')) +\ngeom_point(alpha=0.5) +\ngeom_smooth(method='lm') +\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nTake a moment to run the code and see the result.\n\nWhat do you observe? By default, geom_smooth() creates a regression line for each continent, and plotnine even adds confidence intervals—those shaded gray areas around the lines. These intervals give us an idea of how well the model fits the data.\nWe also used the alpha argument to make our points semi-transparent. Why? It reduces visual clutter and lets the trend lines stand out more. Did you know that transparency can also be mapped to a variable? That’s right—just like color or size, you can use alpha as a mapping aesthetic to make transparency vary based on your data. Try experimenting with that later!\nHere’s a task for you: Modify the code we just used so that instead of creating separate regression lines for each continent, plotnine creates a single trend line for all data points.\nHere’s the code to start with:\n\n\n\n\n\n\nChallenge\n\n\n\nCreate a single regression line for all data points modifying this sample code\n(\nggplot(gapminder, mapping = aes(x='gdpPercap', y='lifeExp', color='continent'))+\ngeom_point(alpha=0.5)+\ngeom_smooth(method='lm')+\nscale_x_log10()\n)\n\n\nTake a moment to think about it. How can you combine the points colored by continent with a single global regression line?\nThere’s more than one way to solve this problem—see what you can come up with!\nDid you find this challenge hard? It’s ok! Let’s step through it together!\nIn our previous example, we declared all the mappings—x, y, and color—at the global level, in the ggplot() function. This means that every layer inherited these mappings. While this works well for most situations, it’s not what we need here.\nTo build a single trend line for all data points, we must ensure that the color aesthetic applies only to the points and not to the trend line. How do we do that? By moving the color mapping from the global level into the geom_point() function.\nHere’s how the updated code looks:\n\n(\nggplot(gapminder, mapping = aes(x='gdpPercap', y='lifeExp'))+\ngeom_point(aes(color='continent'), alpha=0.5)+\ngeom_smooth(method='lm')+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nBy moving the color aesthetic into geom_point(), it now affects only the points layer. Notice that it’s still wrapped in the aes() function because it remains a data-linked property. Meanwhile, the trend line—added by geom_smooth()—inherits only the global mappings for x and y. This creates a single linear model across all continents, as we wanted.\nTake a moment to observe how this subtle adjustment changes the visualization and makes the trend line easier to interpret.\nSome of you might have come up with an alternative solution. Instead of changing the color aesthetic’s scope, we can override it directly within the geom_smooth() layer. In this case, the color aesthetic remains global, but we specify a non-data-linked property for the trend line, such as making it black:\n\n(\nggplot(gapminder, mapping = aes(x='gdpPercap', y='lifeExp', color='continent'))+\ngeom_point(alpha=0.5)+\ngeom_smooth(method='lm', color='black')+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nHere, geom_smooth() ignores the global color aesthetic and instead applies the color black uniformly to the trend line. The result? A single black trend line stands out clearly, while the points remain color-coded by continent.\nBoth approaches work well, and the choice depends on how you want to structure your code and highlight different layers. Managing global and layer-specific mappings is a powerful feature in plotnine that gives you flexibility in creating clean, insightful plots."
  },
  {
    "objectID": "visualization.html#factors",
    "href": "visualization.html#factors",
    "title": "Visualization",
    "section": "Factors",
    "text": "Factors\nDo you want to learn a nifty trick that can improve your data visualization? This method can be useful when you want to visualize a continuous variable which has a limited number of distinct values.\nImagine we’re working with year, which is technically a continuous variable. But for some visualizations it might make more sense to treat each year as a separate category. How do we do that without modifying the data?\nSimple! Instead of referencing year as a string ('year'), wrap it in factor(), like this 'factor(year)'. This shorthand plotnine function converts a continuous variable into a categorical one on the fly, with each distinct value treated as its own category.\nLet’s put this into practice with a couple of challenges!\nCreate a boxplot of life expectancy over time, treating year as a categorical variable. Using this plot, can you detect when the interquartile range of life expectancy—the middle 50% of values—was the smallest?\nThen apply the same concept to gdpPercap.\nCreate a boxplot of GDP per capita by year, but this time keep it on a logarithmic scale. Remember that we used the scale_y_log10() function to make the data easier to interpret. Compare the interquartile range of GDP per capita in 2007 with that in 1952. Is the world today more or less diverse in terms of economic inequality?\n\n\n\n\n\n\nChallenge\n\n\n\n\nMake a boxplot of life expectancy by year. When was interquartile range of life expectancy the smallest?\nMake the same plot of gdpPercap (on a log scale) per year. Is the world today more or less diverse than in 1952?\n\n\n\nGo ahead and give it a try. Pause the video and come back once you have your answer!\n\n(\nggplot(gapminder)+\ngeom_boxplot(mapping = aes(x='factor(year)', y='lifeExp', group='year'))\n)\n\n\n\n\n\n\n\n\n\n(\nggplot(gapminder)+\ngeom_boxplot(mapping = aes(x='factor(year)', y='gdpPercap', group='year')) +\nscale_y_log10()\n)\n\n\n\n\n\n\n\n\nLooking at these two plots, you might notice a fascinating pattern.\nYou’re absolutely right: economic inequality has grown in the recent decades. In 1952, the world was much poorer, but there was a greater sense of uniformity across nations. By 2007, while the world is significantly wealthier on average, the disparities have widened.\nAnd those outliers? Intriguing, aren’t they? Three countries stand apart from the rest in the 1952. Which ones could they be? We’ll revisit these mysteries after diving into data wrangling techniques.\nGreat work on these challenges! These exercises show the power of visualizing data in different ways and how little tricks like factor() can make your plots much clearer. Next, we’ll explore other types of plots that can uncover even more insights. Stay tuned, and I’ll see you in the next lesson!"
  },
  {
    "objectID": "visualization.html#more-geoms",
    "href": "visualization.html#more-geoms",
    "title": "Visualization",
    "section": "More geoms",
    "text": "More geoms\nBy now, you’ve learned so much about using plotnine to create insightful visualizations. But we’ve barely scratched the surface!\nOne of the most exciting features of plotnine is the sheer variety of geoms—the building blocks for visualizing data. Start typing geom_ in your code editor, and you’ll see a list of options pop up. It’s like a treasure chest of possibilities, and each geom offers a unique perspective on your data.\nLet’s put your skills to the test with a few new challenges!\nHistograms are perfect for exploring the distribution of a single variable. Let’s start with life expectancy. Create a histogram and observe the shape of the distribution. How many peaks—or modes—does it have? Play around with the bins parameter. Adjusting the number of bins changes the granularity of your histogram, which can affect how you interpret the distribution. What value of bins seems reasonable to you?\n\n\n\n\n\n\nChallenge\n\n\n\nMake a histogram of life expectancy. What is the shape of the distribution? How many modes (peaks) does the distribution of life expectancy have? What value of the bins parameter look reasonable?\n\n\n\n(\nggplot(gapminder)+\ngeom_histogram(mapping = aes(x='lifeExp'), bins=100)\n)\n\n\n\n\n\n\n\n\nNext up: density plots. These are smoothed-out versions of histograms, showing the probability distribution of your data.\nCreate a simple density plot for life expectancy. You can do it! Start typing and you will find the function you need. Do you see it? What if you want to compare distributions across continents? Add a color aesthetic.\n\n\n\n\n\n\nChallenge\n\n\n\nBuild a density function. How would you compare density functions of different continents?\n\n\n\n(\nggplot(gapminder)+\ngeom_density(mapping = aes(x='lifeExp'))\n)\n\n\n\n\n\n\n\n\n\n(\nggplot(gapminder)+\ngeom_density(mapping = aes(x='lifeExp', color='continent'))\n)\n\n\n\n\n\n\n\n\nRight! You can split the data by continent by adding a color aesthetic and linking it to the variable continent. Or take it one step further! Use the fill aesthetic (in addition to color) to fill the areas under the curves. Add some transparency with alpha for a cleaner visualization like this:\n\n(\nggplot(gapminder)+\ngeom_density(mapping = aes(x='lifeExp', color='continent', fill='continent'), alpha=0.3)\n)\n\n\n\n\n\n\n\n\nThese plots help us see how life expectancy varies not just overall, but also within each continent. Notice any interesting patterns? What might explain the peaks—or modes—you see in the distributions?\nNow let’s level up with 2D density plots. These are excellent for visualizing relationships between two variables. Start by creating a density plot of log GDP per capita vs. life expectancy (use geom_density_2d() function):\n\n\n\n\n\n\nChallenge\n\n\n\nBuild a graph using geom_density2d() for log GDP per capita vs life expectancy. How many clusters of datapoints can you identify? What if you look at it by continent?\n\n\n\n(\nggplot(gapminder)+\ngeom_density_2d(mapping = aes(x='gdpPercap', y='lifeExp'))+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nWhat do you see? Notice the two distinct clusters? One cluster represents countries that are poorer and have lower life expectancy, while the other includes those that are wealthier and healthier.\nNow let’s break it down by continent.\n\n\n\n\n\n\nChallenge\n\n\n\nAdd a color aesthetic to see how regions of the world are distributed\n\n\n\n(\nggplot(gapminder)+\ngeom_density_2d(mapping = aes(x='gdpPercap', y='lifeExp', color='continent'))+\nscale_x_log10()\n)\n\n\n\n\n\n\n\n\nIsn’t that fascinating? The lower cluster is primarily made up of African countries, while the higher cluster mostly includes Europe and Oceania. Asia? It’s scattered across both clusters, reflecting its diversity in economic and health outcomes. These exercises highlight the flexibility and power of plotnine. Whether it’s histograms, density plots, or advanced 2D density visualizations, each plot adds a new layer of understanding to your data."
  },
  {
    "objectID": "visualization.html#faceting",
    "href": "visualization.html#faceting",
    "title": "Visualization",
    "section": "Faceting",
    "text": "Faceting\nWhen your graph starts to feel a bit too crowded—perhaps with too many layers or overlapping aesthetics—there’s a simple solution: faceting. Faceting allows you to split your data into separate panels, creating multiple similar graphs for subsets of your data. This can make complex trends easier to spot and comparisons much clearer.\nIn plotnine, faceting is incredibly easy to use. Let’s revisit one of our earlier graphs and apply faceting to organize it by continent.\n\n(\nggplot(gapminder, mapping = aes(x = 'gdpPercap', y = 'lifeExp')) +\n  geom_point() +\n  geom_smooth(color=\"blue\") +\n  scale_x_log10() + \n  facet_wrap('continent')\n)\n\n\n\n\n\n\n\n\nHere’s what’s happening:\n\nfacet_wrap('continent') instructs plotnine to create a separate panel for each unique value in the continent column.\nPanels are arranged from left to right, and when they don’t fit on one row, they “wrap” onto the next line.\n\nThe result? A clean, organized set of charts where each panel highlights the GDP-per-capita and life expectancy trends for a specific continent. Faceting is especially helpful when the number of panels is manageable, and it lets us compare trends within each group side by side.\nLet’s take this idea further. What happens to the relationship between GDP per capita and life expectancy over time?\nTry faceting by year instead of continent.See if you can answer these questions\n\n\n\n\n\n\nQuestion\n\n\n\n\nDo the slopes of the trend lines change over the years?\nHow does the clustering of data points evolve as time progresses?\n\n\n\nThis exercise offers an incredible opportunity to see how historical events, global growth, and inequality have shaped the world over decades.\n\n\n\n\n\n\nChallenge\n\n\n\nFacet the following plot by year, keeping the linear smoother. You can edit this sample code\n(\nggplot(gapminder, mapping = aes(x = 'gdpPercap', y = 'lifeExp')) +\n  geom_point() +\n  geom_smooth(color='blue') +\n  scale_x_log10() + \n  facet_wrap('continent')\n)\n\n\n\n# facet by year\n(\nggplot(data = gapminder, mapping = aes(x = 'gdpPercap', y = 'lifeExp')) +\n  geom_point() +\n  geom_smooth(color='blue') +\n  scale_x_log10() + \n  facet_wrap('year')\n)\n\n\n\n\n\n\n\n\nWith everything we’ve learned so far, we can summarize the plotnine template as follows::\n(\nggplot(&lt;DATA&gt;) + \n  &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) + \n  &lt;SCALE_FUNCTION&gt; +\n  &lt;FACET_FUNCTION&gt;\n)\nFaceting is a powerful addition to your visualization toolkit, especially when your data has distinct groups or categories. Whether you’re analyzing trends over continents or time, faceting can make your insights clearer and more impactful.\nSo, go ahead—try faceting your own graphs. You’ll be amazed at what you uncover!"
  },
  {
    "objectID": "visualization.html#labeling-and-styling-the-chart",
    "href": "visualization.html#labeling-and-styling-the-chart",
    "title": "Visualization",
    "section": "Labeling and styling the chart",
    "text": "Labeling and styling the chart\nWe’ve built our chart layer by layer, and now it’s time to refine it for presentation—whether for your boss, a client, or publication. The final touches, like annotations and labels, can make all the difference in ensuring your audience understands your insights clearly.\nLet’s start with some practical data transformations. Instead of showing GDP per capita in raw numbers, wouldn’t it be better to express it in thousands of dollars? Similarly, population is easier to interpret when expressed in millions.\nWith plotnine, we don’t need to preprocess our data for this. You can specify transformations directly in your chart code. For example gdpPercap/1e3 divides GDP per capita by 1,000, and uses scientific notation (1e3) for convenience. Similarly, you can use pop/1e6 to show population in millions.\nTo make our chart clear and professional, we’ll use the labs() function. This function gathers all labels in one place, allowing us to customize:\n\nTitle and subtitle at the top,\nCaption at the bottom,\nLabels for x, y, and any mapped aesthetics, like color or size.\n\nHere’s an example of a polished, annotated chart:\n\n(\nggplot(data = gapminder) + \n  geom_point(mapping = aes(x = 'gdpPercap/1e3', y = 'lifeExp', size='pop/1e6', color='continent')) +\n  scale_x_log10() +\n  facet_wrap('year') + \n  labs(title=\"Life Expectancy vs GDP per capita over time\",\n        subtitle=\"In the past 50 years, life expectancy has improved in the world\",\n        caption=\"Source: Gapminder foundation, www.gapminder.org\",\n        x=\"GDP per capita, '000 USD\",\n        y=\"Life expectancy, years\",\n        color=\"Continent\",\n        size=\"Population, mln\")\n)\n\n\n\n\n\n\n\n\nEach label corresponds to the aesthetics used in the aes() mappings. Make sure all mapped aesthetics are labeled, even if they appear in just one layer.\nNow, let’s make your chart stand out! plotnine offers pre-selected themes that adjust the colors, fonts, and overall style of your plots.\nOne of my favorites is theme_minimal(). It simplifies the design, creating a clean and modern look:\n\n(\nggplot(data = gapminder) + \n  geom_point(mapping = aes(x = 'gdpPercap/1e3', y = 'lifeExp', size='pop/1e6', color='continent')) +\n  scale_x_log10() +\n  facet_wrap('year') + \n  labs(title=\"Life Expectancy vs GDP per capita over time\",\n        subtitle=\"In the past 50 years, life expectancy has improved in the world\",\n        caption=\"Source: Gapminder foundation, www.gapminder.org\",\n        x=\"GDP per capita, '000 USD\",\n        y=\"Life expectancy, years\",\n        color=\"Continent\",\n        size=\"Population, mln\") +\n  theme_minimal()\n)\n\n\n\n\n\n\n\n\nplotnine offers plenty of built-in themes to match your purpose:\n\ntheme_dark() for a sleek, high-contrast look.\ntheme_linedraw() for a simple, hand-drawn aesthetic.\ntheme_xkcd() for a playful, comic-style appearance.\ntheme_538() for a polished, professional newsroom feel.\n\nThemes contributed by the community can add even more variety. So, explore, experiment, and find the one that best suits your data story.\nCongratulations!\nYou’ve learned about aesthetics, scales, different types of geoms and now you also know how to annotate and apply themes to your visuals to make them more compelling. With these skills, you’re ready to create polished, professional-quality charts that truly stand out.\nGood luck, and we can’t wait to see the insights you’ll uncover!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Literacy with Python",
    "section": "",
    "text": "Welcome to Data Literacy with Python!\nLet me ask you something: Can you imagine living in today’s world but being unable to read? Think about it—street signs wouldn’t make sense, advertisements would just be noise, and most of the internet? Completely out of reach.\nNow, even with videos and voice assistants everywhere, written text is still the backbone of how we communicate and navigate life. Without it, you’d feel lost.\nBut here’s the thing: today’s world doesn’t just run on words. It runs on data.\nEvery day, we’re creating over 400 million terabytes of data. That’s every single day. And here’s a wild stat—90% of all the world’s data was created in just the last two years.\nThis explosion of information is transforming how we make decisions, whether it’s in business, science, or society as a whole. But here’s the catch: to keep up, you need to know how to make sense of it.\nData isn’t just numbers on a screen—it’s stories waiting to be uncovered. And understanding data has become just as important as being able to read or write.\nThat’s where this course comes in.\nWe’re going to teach you how to take raw, messy data and turn it into something meaningful. You’ll work with rectangular data—the kind you find in spreadsheets or databases.\nAnd don’t worry—this isn’t just about working with numbers. It’s about answering real-world questions, solving problems, and making decisions based on insights you uncover.\nBy the end of this course, you’ll have the skills to transform data into knowledge.\nLet’s talk about the tools you need to work with data.\nYou might be tempted by low-code or no-code solutions—those point-and-click interfaces that make everything seem so easy. And sure, they’re great for quick wins. But when it comes to serious data analysis, they have some big limitations.\nHere’s the thing: data analysis isn’t just about getting answers—it’s about getting credible answers.\nTo trust your insights, you need to leave a trail. Think about it—during analysis, you make dozens of tiny decisions:\nEvery decision shapes your results. And if you—or anyone else—can’t retrace those steps, how can you be sure your conclusions hold up?\nThat’s why scripting your analysis is so important.\nWith a script, every step is recorded. You can spot mistakes, refine your work, or pick up right where you left off—even months later. Low-code tools? They don’t give you that kind of transparency.\nSo, what’s the best language for scripting your data analysis?\nThe answer is Python.\nPython is the world’s most popular programming language, and for good reason. Created in 1990 by Guido van Rossum, Python has become the go-to language for everything from building websites to powering cutting-edge AI. It may not be the fastest language out there, but it’s arguably the most readable. And in today’s data-driven world, readability matters more than ever.\nThe Python ecosystem for data analysis is enormous. Whatever your question, there’s a good chance Python has a library—or ten—that can help.\nData analysis is unique—it’s less about traditional programming and more about crafting a story with your data. Your code should be clear and intuitive, not just for you, but for anyone who needs to understand your work.\nAnd that includes “future you”—because six months from now, you might not even recognize your own analysis without clear documentation!\nSo, as we dive into this course, we’ll emphasize simplicity, transparency, and readability. Because great analysis isn’t just about crunching numbers—it’s about telling a story that stands the test of time.\nData analysis is evolving.\nToday, some of the most cutting-edge tools are built on high-performance programming languages like Rust, Java, or C++. Why? Because these languages are fast—lightning fast. But here’s the best part: you don’t need to write in these languages to enjoy their benefits.\nModern tools now separate the user interface from the engine. That means the algorithms working behind the scenes are the same, no matter which scripting language you use.\nInitiatives like Apache Arrow go even further—they create standardized data formats, making it easy to move between tools and platforms without losing performance or compatibility.\nIn this course, we’re diving into tools built on Rust—one of the fastest, most efficient programming languages out there. Specifically, we’ll use uv for managing packages and environments and polars for data wrangling.\nThese tools are not just fast—they’re scalable.\nThe examples we’ll explore together are small—easy to follow and understand. But don’t let that fool you. The same tools we use here can scale effortlessly to handle datasets with billions of rows, processed across dozens of parallel machines.\nWhat’s even better? The interface doesn’t change.\nSo whether you’re working on a personal project, academic research, or a large-scale business application, the skills you gain here will translate directly to the real world.\nThe datasets may be small, but the questions and challenges we tackle are universal. By the end of this course, you’ll be equipped to uncover meaningful insights from your own data, no matter its size or complexity.\nLet’s get started on this exciting journey into the world of data literacy!"
  },
  {
    "objectID": "index.html#shell",
    "href": "index.html#shell",
    "title": "Data Literacy with Python",
    "section": "Shell",
    "text": "Shell\n\n\n\n\n\n\nObjective\n\n\n\nLaunch command line terminal in every OS"
  },
  {
    "objectID": "index.html#installing-uv",
    "href": "index.html#installing-uv",
    "title": "Data Literacy with Python",
    "section": "Installing uv",
    "text": "Installing uv\n\n\n\n\n\n\nObjective\n\n\n\nInstall uv.\n\n\nWheres my terminal\nWe will install the main tool. Open the terminal and run\n# On macOS and Linux.\n$ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows.\n$ powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\nAlternative attempts to deal with installation problems\nIf you have python and pip install using pip (you will never need it again)\n# With pip.\n$ pip install uv\nOn Mac it can be built with Homebrew\n# using Homebrew on Mac\n$ brew install uv\n\n\n\n\n\n\nNote\n\n\n\nBefore you proceed, please check that installation is successful by running uv in the terminal. You should see something like this\nuv\n\n#&gt; An extremely fast Python package manager.\n#&gt;\n#&gt; Usage: uv [OPTIONS] &lt;COMMAND&gt;\n#&gt; \n#&gt; Commands:\n#&gt;  run      Run a command or script\n#&gt;  init     Create a new project\n#&gt;  ..."
  },
  {
    "objectID": "index.html#managing-python-installation",
    "href": "index.html#managing-python-installation",
    "title": "Data Literacy with Python",
    "section": "Managing python installation",
    "text": "Managing python installation\n\n\n\n\n\n\nObjective\n\n\n\nInstall Python using uv\n\n\nuv is not only powerful package and environment manager, but it also can help manage Python installations. Run the following to see if uv can detect an existing Python installation in your system.\n$ uv python find\n#&gt; /path/to/your/installation/of/bin/python3\nIf no path is returned you can easily install uv-managed latest version of Python with\n$ uv python install"
  },
  {
    "objectID": "index.html#on-files-and-folders",
    "href": "index.html#on-files-and-folders",
    "title": "Data Literacy with Python",
    "section": "On files and folders",
    "text": "On files and folders\n\n\n\n\n\n\nObjective\n\n\n\nUnderstand folders. Decide on location for projects. Navigate there in command line\n\n\nThe files on your computer are organized into folders. Your operating system managed most of the files on your computer but there are still quite a lot of files that you can create and use. You probably written some Word documents or made Excel tables. If you did, you probably know how important it is to remember where you saved your work, so that you can quickly find it.\nWhen working with data analysis you will produce quite a few files. You will need to save your scripts, you will probably have some datasets you are going to use. At the end you probably want to produce some reports and data visualization. It means that a lot of files will be produced all related to the same project you are working on.\nIt is, therefore, important to not disperse these file all over your computer, but make sure that they are easily locatable together.\nThe way operating system organizes the files on your computer is by using folders. Folders are nested containers of other files and folders which is best visualized as a tree. Open a file explorer on your computer and lets have a quick look\nIf you are on Windows, your file explorer may look something like this, if you are on Mac, your explorer will look like this and if you are on Linux you probably have something like this on your computer.\nThe folders are easily recognizable by their distinct icon, but most importantly, if you click on one of those folders you will “drop down” inside of it and you will see its content often with more files and folders.\nOn every operating system there’s usually a place where your computer expects you to place your files.\nThe folders dedicated to user files are usually split by type. In your file explorer you can probably find a folder for music, documents, pictures, videos, and downloads, where as we say it in academia “PDF files go to die”.\nOne special folder present in all operating systems is called Desktop. This is the folder, which content will be visible if you minimize all windows. Even though it is very convenient, most experts would agree that Desktop is not the best place to store your work long term. You can probably keep there a file or two you are currently working on, but you probably need to have a long-term home for your files to keep your Desktop free from clutter. We definitely do not recommend starting your data analysis project inside the Desktop folder.\n\nWhere should you place your data analysis work? I think the documents folder is a solid way to start. If your Documents folder is synched to the cloud, as the case often is on Windows or Mac, you might consider whether it is the right place to store your project files. Data analysis project tend to grow big and while back up for source files is important you may not want to take up your valuable cloud quota, which could be better used by your work documents and presentations.\nAlternatively, you can create a folder on the same level as your documents and downloads, called, for example, Projects and host your data science projects there. We will learn about version control for source code, which helps you keep track of changes, so the task of backing up your work will be taken care of by Git and GitHub, which we will introduce in Lesson 5.\nWherever you decide to place your work, make sure it is easily locatable. In the next section we will talk about organizing your work in project folders, which ensure that your work is tidy and reproducible.\nNavigating to project location using command line (ls, cd and cd ..)."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Data Literacy with Python",
    "section": "Projects",
    "text": "Projects\n\n\n\n\n\n\nObjective\n\n\n\nCreate project.\n\n\nEach of your data analysis endeavours should be stored in a separate project folder.\n$ uv init data-literacy-project\ncd data-literacy-project\nor alternatively\n$ mkdir data-literacy-project\n$ cd data-literacy-project\n$ uv init"
  },
  {
    "objectID": "index.html#libraries",
    "href": "index.html#libraries",
    "title": "Data Literacy with Python",
    "section": "Libraries",
    "text": "Libraries\n\n\n\n\n\n\nObjective\n\n\n\nAdd dependencies\n\n\nWe will need a few libraries. Lets add them\n$ uv add gapminder plotnine polars jupyter great_tables setuptools ipykernel pyyaml nbformat nbclient\nIf you did these steps then you should have a file data-literacy-project/pyproject.toml which looks something like this\n[project]\nname = \"data-literacy-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\ndependencies = [\n    \"gapminder&gt;=0.1\",\n    \"ipykernel&gt;=6.29.5\",\n    \"jupyter&gt;=1.1.1\",\n    \"plotnine&gt;=0.13.6\",\n    \"polars&gt;=1.8.2\",\n    \"setuptools&gt;=75.1.0\",\n]"
  },
  {
    "objectID": "index.html#activation",
    "href": "index.html#activation",
    "title": "Data Literacy with Python",
    "section": "Activation",
    "text": "Activation\nFinally we need to activate the environment we created\nsource .venv/bin/activate"
  },
  {
    "objectID": "pivotjoin.html",
    "href": "pivotjoin.html",
    "title": "Pivots and joins",
    "section": "",
    "text": "import polars as pl\nimport polars.selectors as cs\nfrom plotnine import *\nfrom gapminder import gapminder\nfrom great_tables import GT\ntheme_set(theme_linedraw())"
  },
  {
    "objectID": "pivotjoin.html#pivot",
    "href": "pivotjoin.html#pivot",
    "title": "Pivots and joins",
    "section": "Pivot",
    "text": "Pivot\nEarlier we mentioned that data frame consists of observations organized in rows and variable organized in columns. But not all data comes as well-organized as wel would want it to be. Today we are going to look at the sample of the data collected by the Break from Plastics environmental campaign. Here’s the description of the data:\n\nIn 2020, thanks to our members and allies, Break Free From Plastic engaged 14,734 volunteers in 55 countries to conduct 575 brand audits. These volunteers collected 346,494 pieces of plastic waste, 63% of which was marked with a clear consumer brand. Despite the challenges of organizing during a global pandemic, our volunteers safely coordinated more brand audit events in more countries this year than in the previous two years. As a special activity during the pandemic, we also worked with over 300 waste pickers to highlight their roles as essential workers. Participants catalogued over 5,000 brands in this year’s global audit. Our analysis reveals the following as the 2020 Top 10 Global Polluters: The Coca-Cola Company; PepsiCo; Nestlé; Unilever; Mondelez International; Mars, Inc.; Procter & Gamble; Philip Morris International; Colgate-Palmolive; and Perfetti Van Melle.\n\nWe are going to investigate this dataset and summarize it using Great Tables. Great Tables is a python package which implements “grammar of tables”, so in many respects it is similar in spirit to plotnine, in a sense that it attempts to develop a consistent API around production of tables making it very easy to produce nice looking summaries form data in table form. The main function in Great Tables is GT(). It takes data argument and many other useful options. We can use .pipe to pass the data into it.\nIn the code example provided to you in the notebook you can see the code for importing the data, as well as the dataframe containing the data dictionary for this dataset. The data frame is specified via a dictionary denoted with curly braces {}. Dictionaries are widely used in Python for passing “key-value” pairs.\n\nplastics_df = pl.read_csv(\"bffp/BFFplastics.csv\")\n\nplastics_docs = pl.DataFrame({\n    \"Variable\": [\"region\", \"country_code\" , \"country\", \"year\", \"parent_company\", \"empty\", \"hdpe\", \"ldpe\", \"o\", \"pet\", \"pp\", \"ps\", \"pvc\", \"grand_total\", \"num_events\", \"volunteers\"],\n    \"Class\": [\"character\",\"character\",\"character\", \"double\", \"character\", \"double\", \"double\", \"double\", \"double\", \"double\", \"double\", \"double\", \"double\", \"double\", \"double\", \"double\"],\n    \"Description\": [\"Region\", \"Alpha 3 ISO 3166 code\",\"Country of cleanup\", \"Year (2019 or 2020)\", \"Source of plastic\", \"Category left empty count\", \"High density polyethylene count (Plastic milk containers, plastic bags, bottle caps, trash cans, oil cans, plastic lumber, toolboxes, supplement containers)\", \"Low density polyethylene count (Plastic bags, Ziploc bags, buckets, squeeze bottles, plastic tubes, chopping boards)\", \"Category marked other count\", \"Polyester plastic count (Polyester fibers, soft drink bottles, food containers (also see plastic bottles)\", \"Polypropylene count (Flower pots, bumpers, car interior trim, industrial fibers, carry-out beverage cups, microwavable food containers, DVD keep cases)\", \"Polystyrene count (Toys, video cassettes, ashtrays, trunks, beverage/food coolers, beer cups, wine and champagne cups, carry-out food containers, Styrofoam)\", \"PVC plastic count (Window frames, bottles for chemicals, flooring, plumbing pipes)\", \"Grand total count (all types of plastic)\", \"Number of counting events\", \"Number of volunteers\"]\n})\n\n(plastics_docs\n    .pipe(GT)\n)\n\n(plastics_df.describe())\n\n\nshape: (9, 17)\n\n\n\nstatistic\nregion\ncountry_code\ncountry\nyear\nparent_company\nempty\nhdpe\nldpe\no\npet\npp\nps\npvc\ngrand_total\nnum_events\nvolunteers\n\n\nstr\nstr\nstr\nstr\nf64\nstr\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n\"count\"\n\"12034\"\n\"12034\"\n\"12034\"\n13380.0\n\"13330\"\n10137.0\n11734.0\n11303.0\n13113.0\n13166.0\n11884.0\n11408.0\n9052.0\n13366.0\n13380.0\n13273.0\n\n\n\"null_count\"\n\"1346\"\n\"1346\"\n\"1346\"\n0.0\n\"50\"\n3243.0\n1646.0\n2077.0\n267.0\n214.0\n1496.0\n1972.0\n4328.0\n14.0\n0.0\n107.0\n\n\n\"mean\"\nnull\nnull\nnull\n2019.305232\nnull\n0.411759\n3.04602\n10.319384\n49.61359\n20.940301\n8.220801\n1.862114\n0.350088\n90.15083\n33.369806\n1117.645295\n\n\n\"std\"\nnull\nnull\nnull\n0.460523\nnull\n22.586066\n66.123044\n194.644067\n1601.989534\n428.157766\n141.805081\n39.737064\n7.894296\n1873.68134\n44.708642\n1812.402748\n\n\n\"min\"\n\"Africa\"\n\"ARE\"\n\"Argentina\"\n2019.0\n\"\"ESE\"\"\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n1.0\n\n\n\"25%\"\nnull\nnull\nnull\n2019.0\nnull\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n4.0\n114.0\n\n\n\"50%\"\nnull\nnull\nnull\n2019.0\nnull\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n15.0\n400.0\n\n\n\"75%\"\nnull\nnull\nnull\n2020.0\nnull\n0.0\n0.0\n0.0\n2.0\n0.0\n0.0\n0.0\n0.0\n6.0\n42.0\n1416.0\n\n\n\"max\"\n\"Western Pacific\"\n\"ZAF\"\n\"Viet Nam\"\n2020.0\n\"脆司令/Cui Siling\"\n2208.0\n3728.0\n11700.0\n120646.0\n36226.0\n6046.0\n2101.0\n622.0\n120646.0\n145.0\n31318.0\n\n\n\n\n\n\nThere are many missing values in this data. The year column covers 2019 and 2020. The different plastics types exibit different degrees of missingness.\nFirst have a look at the data\n\nplastics_df\n\nplastics_df.filter(pl.col(\"country\").is_null())\n\n\nshape: (1_346, 16)\n\n\n\nregion\ncountry_code\ncountry\nyear\nparent_company\nempty\nhdpe\nldpe\no\npet\npp\nps\npvc\ngrand_total\nnum_events\nvolunteers\n\n\nstr\nstr\nstr\ni64\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\nnull\nnull\nnull\n2019\n\"Grand Total\"\nnull\n1535\n6443\n30181\n11087\n5420\n2101\n188\n56955\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"Unbranded\"\nnull\n631\n3176\n17432\n4265\n2417\n1545\n20\n29486\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"The Coca-Cola Company\"\nnull\n130\n4\n157\n1154\n210\n1\n51\n1707\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"Philip Morris\"\nnull\n13\n37\n1579\n1\n0\n4\n0\n1634\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"Sahakari Jal\"\nnull\n0\n0\n0\n563\n975\n0\n0\n1538\n145\n1416\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\nnull\nnull\nnull\n2019\n\"Schulte\"\nnull\n0\n0\n1\n0\n0\n0\n0\n1\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"Schwartau\"\nnull\n0\n1\n0\n0\n0\n0\n0\n1\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"SchÃ¶fferhofer\"\nnull\n0\n0\n1\n0\n0\n0\n0\n1\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"Scotts Black Mulch\"\nnull\n0\n1\n0\n0\n0\n0\n0\n1\n145\n1416\n\n\nnull\nnull\nnull\n2019\n\"Cherry Valley marketplace\"\nnull\n0\n0\n1\n0\n0\n0\n0\n1\n145\n1416\n\n\n\n\n\n\nLook at the very first row. The parent_company is Grand Total. It seems like this line contains the totals for Argentinian records for 2019.\nHowever, for year 2020, the rows with totals per country are not marked with “Grand Total”, but rather are populated with the missing value\n\n(plastics_df\n    .filter(pl.col(\"year\")==2020))\n\n\nshape: (4_084, 16)\n\n\n\nregion\ncountry_code\ncountry\nyear\nparent_company\nempty\nhdpe\nldpe\no\npet\npp\nps\npvc\ngrand_total\nnum_events\nvolunteers\n\n\nstr\nstr\nstr\ni64\nstr\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n\"Americas\"\n\"ARG\"\n\"Argentina\"\n2020\nnull\n0\n12\n9\n70\n9\n7\n2\n0\n109\n24\n9\n\n\n\"Americas\"\n\"ARG\"\n\"Argentina\"\n2020\n\"Aceitera Martinez S.A\"\n0\n0\n0\n0\n1\n0\n0\n0\n1\n24\n9\n\n\n\"Americas\"\n\"ARG\"\n\"Argentina\"\n2020\n\"AGD\"\n0\n0\n0\n3\n1\n0\n0\n0\n4\n24\n9\n\n\n\"Americas\"\n\"ARG\"\n\"Argentina\"\n2020\n\"Alfredo Willliner S.A\"\n0\n0\n0\n0\n0\n0\n2\n0\n2\n24\n9\n\n\n\"Americas\"\n\"ARG\"\n\"Argentina\"\n2020\n\"Alicorp Argentina\"\n0\n0\n0\n0\n0\n1\n0\n0\n1\n24\n9\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Western Pacific\"\n\"VNM\"\n\"Viet Nam\"\n2020\n\"Vinamilk\"\n0\n0\n0\n91\n1\n0\n0\n0\n92\n6\n27\n\n\n\"Western Pacific\"\n\"VNM\"\n\"Viet Nam\"\n2020\n\"VINH HAO CO.\"\n0\n0\n0\n0\n4\n0\n0\n0\n4\n6\n27\n\n\n\"Western Pacific\"\n\"VNM\"\n\"Viet Nam\"\n2020\n\"Vital\"\n0\n0\n0\n0\n4\n0\n0\n0\n4\n6\n27\n\n\n\"Western Pacific\"\n\"VNM\"\n\"Viet Nam\"\n2020\n\"VM Group\"\n0\n2\n0\n0\n0\n0\n0\n0\n2\n6\n27\n\n\n\"Western Pacific\"\n\"VNM\"\n\"Viet Nam\"\n2020\n\"Yakult\"\n0\n0\n0\n0\n0\n2\n0\n0\n2\n6\n27\n\n\n\n\n\n\nBefore we dive deeper into analyzing top contributors to plastic waste, lets look at the totals per country. We now have two options. We could populate the rows containing the totals with the phrase “Grand Total” and then use it to filter. This assumes that totals are calculated properly for all countries. We will basically disregard the majority of the dataset and rely on few rows that have been pre-computed for us.\nAn alternative strategy could be to drop all rows with invalid company name (marked with either “Grand Total” or left missing “null”) and recompute totals by hand for each of the count columns.\n\nplastics_totals = (plastics_df\n    .drop(\"grand_total\", \"num_events\", \"volunteers\")\n    .filter((pl.col(\"parent_company\")!=\"Grand Total\"),\n            (pl.col(\"parent_company\").is_not_null()))\n    .group_by(\"country\", \"year\")\n    .agg(pl.exclude(\"country\", \"year\", \"parent_company\").drop_nulls().sum())\n    )\n\n\n# LEFT AS AN EXERCISE FOR THE USER\n# fill the missing values in the parent_company column with the phrase \"Grand Total\". \n# Since the parent company column is no longer informative, we can drop it.\nplastics_totals_1 = (plastics_df\n    .drop(\"grand_total\", \"num_events\", \"volunteers\")\n    .with_columns(pl.col(\"parent_company\").fill_null(\"Grand Total\"))\n    .filter(pl.col(\"parent_company\")==\"Grand Total\")\n    .drop(\"parent_company\")\n    )\n# What did we miss?\n(plastics_totals_1\n    .join(plastics_totals, on=[\"country\", \"year\"], how=\"anti\")\n    )\n\n(plastics_totals\n    .join(plastics_totals_1, on=[\"country\", \"year\"], how=\"anti\")\n    )\n\n# does not have row for the total\ntmp1_df = (plastics_df\n    .filter(pl.col(\"country\")==\"Slovenia\",\n            pl.col(\"year\")==2020)\n    )\n\n# does not have any records other than the total\ntmp2_df = (plastics_df\n    .filter(pl.col(\"country\")==\"United Arab Emirates\",\n            pl.col(\"year\")==2020)\n    )\n\ntmp2_df = (plastics_totals\n    .filter(pl.col(\"country\").is_null())\n    )\n\nWe do have grand_total column which seems to be a sum of columns empty:pvc describing counts for different type of plastic. Let’s say our goal is to make a chart describing the composition of trash by plastic type in different countries. In order to calculate proportions as we did previously, we need to have multiple observations for each country, one for each plastic type. Then we will calculate proportion over the country (and year).\n\nplastics_long_df = (plastics_df\n    .drop(\"grand_total\", \"num_events\", \"volunteers\")\n    .with_columns(pl.col(\"parent_company\").fill_null(\"Grand Total\"))\n    .filter(pl.col(\"parent_company\")==\"Grand Total\")\n    .drop(\"parent_company\")\n    #.unpivot(index=[\"country\", \"year\"], variable_name=\"plastic_type\", value_name=\"quantity\")\n    .unpivot(index=cs.by_name(\"country\", \"year\"), variable_name=\"plastic_type\", value_name=\"quantity\")\n    .with_columns(pl.col(\"quantity\").fill_null(0))\n    )\n# In `.unpivot()` the `on` argument is optional. Everything other than index\n\nPivot is making the data wider\n\n(plastics_long_df\n    .pivot(on=\"year\", values=\"quantity\")\n    )\n# In `.pivot()` the `index` is optional. All remaining columns not specified in `on` and `values` will be used.\n# either index or values need to be specified\n\n\nshape: (650, 4)\n\n\n\ncountry\nplastic_type\n2019\n2020\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"Argentina\"\n\"region\"\n\"Americas\"\n\"Americas\"\n\n\n\"Australia\"\n\"region\"\n\"Western Pacific\"\n\"Western Pacific\"\n\n\n\"Bangladesh\"\n\"region\"\n\"South-East Asia\"\nnull\n\n\n\"Benin\"\n\"region\"\n\"Africa\"\n\"Africa\"\n\n\n\"Bhutan\"\n\"region\"\n\"South-East Asia\"\nnull\n\n\n…\n…\n…\n…\n\n\n\"Peru\"\n\"pvc\"\nnull\n\"1\"\n\n\n\"Romania\"\n\"pvc\"\nnull\n\"0\"\n\n\n\"Serbia\"\n\"pvc\"\nnull\n\"0\"\n\n\n\"Singapore\"\n\"pvc\"\nnull\n\"0\"\n\n\n\"Togo\"\n\"pvc\"\nnull\n\"0\"\n\n\n\n\n\n\n\n(plastics_long_df\n    .pivot(on=\"year\", index=\"country\", values=\"quantity\", aggregate_function='sum')\n    )\n\nplastics_campaigns_df = (plastics_long_df\n    .pivot(on=\"year\", index=[\"country\", \"plastic_type\"], values=\"quantity\")\n    .group_by(\"country\")\n    .agg(pl.all().exclude(\"country\", \"plastic_type\").fill_null(0).sum())\n)\n\n(plastics_campaigns_df    \n    .filter(pl.col(\"country\").is_in([\"Germany\", \"Netherlands\", \"Switzerland\", \"France\", \"Spain\", \"Italy\"]))\n    .pipe(GT)\n    .cols_label(\n        country=\"Country\")\n    .tab_spanner(\"Year\", columns=[\"2019\", \"2020\"])\n    .tab_header(\n        title = \"Break Free From Plastics campaigns\",\n        subtitle = \"Brand plastic counts in some European countries\")\n    .tab_source_note(\n        source_note=\"Source: BFFP data via TidyTuesday 2021-01-26\"\n    )\n)\n\n\n\n\n\n\n\nBreak Free From Plastics campaigns\n\n\nBrand plastic counts in some European countries\n\n\nCountry\nYear\n\n\n2019\n2020\n\n\n\n\nSpain\nNone\nNone\n\n\nItaly\nNone\nNone\n\n\nSwitzerland\nNone\nNone\n\n\nFrance\nNone\nNone\n\n\nGermany\nNone\nNone\n\n\n\nSource: BFFP data via TidyTuesday 2021-01-26"
  },
  {
    "objectID": "pivotjoin.html#stacking",
    "href": "pivotjoin.html#stacking",
    "title": "Pivots and joins",
    "section": "Stacking",
    "text": "Stacking\n\n# indoor air pollution\nhhap_deaths = pl.read_csv(\"hhap/hhap_deaths.csv\")\nclean_fuels = pl.read_csv(\"hhap/clean_fuels_cooking.csv\")\nfuel_types = pl.read_csv(\"hhap/cooking_by_fuel_type.csv\")\n\nAnother common type of operation is stacking two identical datasets together (vertically). This is possible to do when the meaning of the columns in the datasets is the same and we are interested in combining two parts of identical data into a new and larger dataset.\nRecall that in our household air pollution case study we had three files: - hhap_deaths - containing death cases, associated with air pollution - fuel_types - describing information about the fuels used by population in different countries for household needs - clean_fuels - containing the fraction of population in each country with access to clean fulels for cooking\nAll three of these datasets contain three identical columns describing the country of observation: region, country_code and country. The countries listed in each of the datasets is largely similar, but not completely overlapping. Let’s see if we can compile a single master set of all countries with the codes and the regions they belong to. Because the data is recorded over many years each of the datasets contains many duplicates entries. This problem will be even larger when we stack the data from several datasets together, so we will need to ensure the records in our final (combined) dataset are unique.\n\nidcols=cs.by_name(\"region\", \"country_code\", \"country\")\ncountry_regions = (hhap_deaths.select(idcols)\n    .vstack(fuel_types.select(idcols))\n    .vstack(clean_fuels.select(idcols))\n    .unique()\n)\n\nNote, that here we created a temporary object idcols, which will store only selector object for the three columns we are interested in. Polar selectors are independent entities which can live both inside the querying contexts as well as in the global environment, i.e. in memory accessible\nLets compare our country codes with the full list of codes issued by ISO. Here’s a file with all Alpha 2 and Alpha 3 codes issued to nation states and territories.\n\niso_df = pl.read_csv(\"hhap/CountryCodes_Alpha2_Alpha3.csv\")\n\n(country_regions\n    .join(iso_df, left_on=\"country_code\", right_on=\"alpha3\", how=\"anti\"))\n\n(country_regions\n    .join(iso_df, left_on=\"country_code\", right_on=\"alpha3\", how=\"left\"))\n\n# How many countries are not present in the combined household air pollution dataset? \n# What proportion of those countries have the world \"Island\" in their name?\n\ntmp_df1 = (iso_df\n    .join(country_regions, left_on=\"alpha3\", right_on=\"country_code\", how=\"anti\"))\n\n(iso_df\n    .join(country_regions, left_on=\"alpha3\", right_on=\"country_code\", how=\"anti\")\n    .select(pl.col(\"country\").str.contains(\"Island\").mean())\n    )\n\n(iso_df\n    .join(country_regions, left_on=\"alpha3\", right_on=\"country_code\", how=\"anti\")\n    .group_by(pl.col(\"country\").str.contains(\"Island\").alias(\"island\"))\n    .len()\n    .with_columns(pl.col(\"len\")/pl.sum(\"len\"))\n    .filter(\"island\")\n    )\n\n\nshape: (1, 2)\n\n\n\nisland\nlen\n\n\nbool\nf64\n\n\n\n\ntrue\n0.259259\n\n\n\n\n\n\nHorizontal stacking is possible, but you probably want to do a join instead, because horizontal stacking assumes that row order is the same and observations are identical. This is better ensured with unique IDs which could be used for join."
  }
]