{"title":"Data Literacy with Python","markdown":{"yaml":{"title":"Data Literacy with Python"},"headingText":"Shell","containsRefs":false,"markdown":"\n\nWelcome to Data Literacy with Python!\n\nLet me ask you something: Can you imagine living in today’s world but being unable to read? Think about it—street signs wouldn’t make sense, advertisements would just be noise, and most of the internet? Completely out of reach.\n\nNow, even with videos and voice assistants everywhere, written text is still the backbone of how we communicate and navigate life. Without it, you'd feel lost.\n\nBut here’s the thing: today’s world doesn’t just run on words. It runs on data.\n\nEvery day, we’re creating over 400 million terabytes of data. That’s every single day. And here’s a wild stat—90% of all the world’s data was created in just the last two years.\n\nThis explosion of information is transforming how we make decisions, whether it’s in business, science, or society as a whole. But here’s the catch: to keep up, you need to know how to make sense of it.\n\nData isn’t just numbers on a screen—it’s stories waiting to be uncovered. And understanding data has become just as important as being able to read or write.\n\n\nThat’s where this course comes in.\n\nWe’re going to teach you how to take raw, messy data and turn it into something meaningful. You’ll work with rectangular data—the kind you find in spreadsheets or databases.\n\nAnd don’t worry—this isn’t just about working with numbers. It’s about answering real-world questions, solving problems, and making decisions based on insights you uncover.\n\nBy the end of this course, you’ll have the skills to transform data into knowledge.\n\nLet’s talk about the tools you need to work with data.\n\nYou might be tempted by low-code or no-code solutions—those point-and-click interfaces that make everything seem so easy. And sure, they’re great for quick wins. But when it comes to serious data analysis, they have some big limitations.\n\nHere’s the thing: data analysis isn’t just about getting answers—it’s about getting credible answers.\n\nTo trust your insights, you need to leave a trail. Think about it—during analysis, you make dozens of tiny decisions:\n\n- Which part of the data should you focus on?\n- What variables should you use?\n- Which patterns caught your eye?\n\nEvery decision shapes your results. And if you—or anyone else—can’t retrace those steps, how can you be sure your conclusions hold up?\n\nThat’s why scripting your analysis is so important.\n\nWith a script, every step is recorded. You can spot mistakes, refine your work, or pick up right where you left off—even months later. Low-code tools? They don’t give you that kind of transparency.\n\nSo, what’s the best language for scripting your data analysis?\n\nThe answer is Python.\n\nPython is the world’s most popular programming language, and for good reason. Created in 1990 by Guido van Rossum, Python has become the go-to language for everything from building websites to powering cutting-edge AI. It may not be the fastest language out there, but it’s arguably the most readable. And in today’s data-driven world, readability matters more than ever. \n\nThe Python ecosystem for data analysis is enormous. Whatever your question, there’s a good chance Python has a library—or ten—that can help.\n\nData analysis is unique—it’s less about traditional programming and more about crafting a story with your data. Your code should be clear and intuitive, not just for you, but for anyone who needs to understand your work.\n\nAnd that includes “future you”—because six months from now, you might not even recognize your own analysis without clear documentation!\n\nSo, as we dive into this course, we’ll emphasize simplicity, transparency, and readability. Because great analysis isn’t just about crunching numbers—it’s about telling a story that stands the test of time.\n\nData analysis is evolving.\n\nToday, some of the most cutting-edge tools are built on high-performance programming languages like Rust, Java, or C++. Why? Because these languages are fast—lightning fast. But here’s the best part: you don’t need to write in these languages to enjoy their benefits.\n\nModern tools now separate the user interface from the engine. That means the algorithms working behind the scenes are the same, no matter which scripting language you use.\n\nInitiatives like Apache Arrow go even further—they create standardized data formats, making it easy to move between tools and platforms without losing performance or compatibility.\n\nIn this course, we’re diving into tools built on Rust—one of the fastest, most efficient programming languages out there. Specifically, we’ll use uv for managing packages and environments and polars for data wrangling.\n\nThese tools are not just fast—they’re scalable.\n\nThe examples we’ll explore together are small—easy to follow and understand. But don’t let that fool you. The same tools we use here can scale effortlessly to handle datasets with billions of rows, processed across dozens of parallel machines.\n\nWhat’s even better? The interface doesn’t change.\n\nSo whether you’re working on a personal project, academic research, or a large-scale business application, the skills you gain here will translate directly to the real world.\n\nThe datasets may be small, but the questions and challenges we tackle are universal. By the end of this course, you’ll be equipped to uncover meaningful insights from your own data, no matter its size or complexity.\n\nLet’s get started on this exciting journey into the world of data literacy!\n\n\n\nBefore we dive into the thrilling world of data analysis, let’s pause and talk about something fundamental: your computer. That’s right, the device you’re watching this on is more than just a tool—it’s the backbone of your data analysis journey. Set it up well, and it will help you create reliable, reproducible, and stunning analytic projects.\n\nBut to unlock its full potential, we need to talk about something that might not look exciting at first glance but is incredibly powerful: the command line—also known as the shell or terminal.\n\nEvery operating system has some version of a terminal. Whether you're on Windows, macOS, or Linux, this is your gateway to greater control over your computer. In the terminal, you don’t rely on menus, buttons, or icons. Instead, you type commands, giving you direct access to your system's capabilities.\n\nNow, if this is new to you, don’t worry! Below this video, you’ll find instructions on how to locate and open the terminal on your operating system. Take a moment to familiarize yourself with launching it, and then meet me back here.\n\nOnce you’re ready, we’ll discuss folders—yes, the simple yet crucial task of organizing your files. If you already know how to navigate your operating system, create new folders, and understand the user directory, feel free to skip ahead to the next video. Otherwise, stick with me, and I’ll walk you through everything you need to know.\n\n:::{.challenge}\nFind and open the terminal on your computer. Take that first step toward becoming a power user!\n:::\n\n## On files and folders\n\nNow that you’ve found your terminal, it’s time to talk about something fundamental to every data analysis project: files and folders.\n\nThink about how your computer organizes everything you create or download—whether it’s a Word document, an Excel spreadsheet, or a photo. These files are stored in folders, and if you’ve ever saved something important, you know how critical it is to remember where it’s located.\n\nWhen working with data analysis, you’ll generate a lot of files—scripts, datasets, reports, visualizations—the list goes on. Keeping all of these files organized and in one place is essential to staying productive. You don’t want to waste time hunting through your computer every time you need something.\n\nHere’s the good news: your operating system already provides a great tool for organizing files—folders. Folders are like containers, and they can even hold other folders. Picture this as a tree, with your main folder as the trunk and subfolders branching out.\n\nLet’s take a moment to explore this on your computer.\n\n- On Windows, you can open File Explorer by clicking the icon on your taskbar or pressing the Windows key + E. Once it’s open, you’ll see something like this:\n\n![](img/win_explorer.png)\n\n- On Mac, you’ll use an app called Finder. Just click its icon in the Dock, and you’ll see a view like this:\n\n![](img/mac_finder.png)\n\n- On Linux, it’s often just called Files, and the interface may vary depending on your distribution. On my Ubuntu setup, it looks like this:\n\n![](img/linux-files.png)\n\nInside these interfaces, folders are easy to spot with their distinct icons. Click on one, and you’ll dive inside to see its contents—maybe more files, maybe more folders.\n\nNow, every operating system has a home base for your personal files. This is typically called your Home folder and contains directories like Music, Pictures, Videos, and Downloads. A special folder called Desktop displays its contents right on your screen.\n\nWhile it’s tempting to store everything on your Desktop for easy access, this isn’t the best long-term solution. A cluttered Desktop can make it harder to stay organized, and let’s be honest—it doesn’t look great either.\n\n![](img/desktop.jpeg)\n\nInstead, consider creating a dedicated folder for your data analysis projects. For example, you could use your Documents folder or create a new folder called Projects. If your Documents folder is synced to the cloud—like with OneDrive or iCloud—think carefully about whether that’s the right place for large datasets. Cloud storage is precious, and you might want to save that space for smaller files like presentations or text documents.\n\nDon’t worry about backups just yet—we’ll cover that later when we dive into version control using Git and GitHub. For now, focus on picking a location that’s tidy, accessible, and works for you.\n\nOnce you’ve chosen your perfect home base, we’ll move on to the next step: learning how to navigate your files and folders using the command line. Trust me, it’s easier than it sounds, and it will make your workflow so much more efficient!\n\n\n## Installing uv\n\n:::{.callout-tip}\n### Objective\nInstall uv.\n:::\n\nWheres my terminal\n\n\nWe will install the main tool. Open the terminal and run\n\n```\n# On macOS and Linux.\n$ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows.\n$ powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nAlternative attempts to deal with installation problems\n\nIf you have python and pip install using pip (you will never need it again)\n\n```\n# With pip.\n$ pip install uv\n```\n\nOn Mac it can be built with Homebrew\n\n```\n# using Homebrew on Mac\n$ brew install uv\n```\n\n::: {.callout-note}\nBefore you proceed, please check that installation is successful by running `uv` in the terminal. You should see something like this\n\n```\nuv\n\n#> An extremely fast Python package manager.\n#>\n#> Usage: uv [OPTIONS] <COMMAND>\n#> \n#> Commands:\n#>  run      Run a command or script\n#>  init     Create a new project\n#>  ...\n```\n\n:::\n\n## Managing python installation\n\n:::{.callout-tip}\n### Objective\nInstall Python using uv\n:::\n\n`uv` is not only powerful package and environment manager, but it also can help manage Python installations. Run the following to see if `uv` can detect an existing Python installation in your system.\n\n```\n$ uv python find\n#> /path/to/your/installation/of/bin/python3\n```\nIf no path is returned you can easily install `uv`-managed latest version of Python with\n\n```\n$ uv python install\n```\n\n\nNavigating to project location using command line (ls, cd and cd ..).\n\n## Projects\n\n:::{.callout-tip}\n### Objective\nCreate project. \n:::\n\nEach of your data analysis endeavours should be stored in a separate project folder. \n\n```\n$ uv init data-literacy-project\ncd data-literacy-project\n```\n\nor alternatively\n\n```\n$ mkdir data-literacy-project\n$ cd data-literacy-project\n$ uv init\n```\n\n## Libraries\n\n:::{.callout-tip}\n### Objective\nAdd dependencies\n:::\n\nWe will need a few libraries. Lets add them \n\n```\n$ uv add gapminder plotnine polars jupyter great_tables setuptools ipykernel pyyaml nbformat nbclient\n```\nIf you did these steps then you should have a file `data-literacy-project/pyproject.toml` which looks something like this\n\n```yaml\n[project]\nname = \"data-literacy-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"gapminder>=0.1\",\n    \"ipykernel>=6.29.5\",\n    \"jupyter>=1.1.1\",\n    \"plotnine>=0.13.6\",\n    \"polars>=1.8.2\",\n    \"setuptools>=75.1.0\",\n]\n```\n\n## Activation\n\nFinally we need to activate the environment we created\n\n```\nsource .venv/bin/activate\n```\n\n","srcMarkdownNoYaml":"\n\nWelcome to Data Literacy with Python!\n\nLet me ask you something: Can you imagine living in today’s world but being unable to read? Think about it—street signs wouldn’t make sense, advertisements would just be noise, and most of the internet? Completely out of reach.\n\nNow, even with videos and voice assistants everywhere, written text is still the backbone of how we communicate and navigate life. Without it, you'd feel lost.\n\nBut here’s the thing: today’s world doesn’t just run on words. It runs on data.\n\nEvery day, we’re creating over 400 million terabytes of data. That’s every single day. And here’s a wild stat—90% of all the world’s data was created in just the last two years.\n\nThis explosion of information is transforming how we make decisions, whether it’s in business, science, or society as a whole. But here’s the catch: to keep up, you need to know how to make sense of it.\n\nData isn’t just numbers on a screen—it’s stories waiting to be uncovered. And understanding data has become just as important as being able to read or write.\n\n\nThat’s where this course comes in.\n\nWe’re going to teach you how to take raw, messy data and turn it into something meaningful. You’ll work with rectangular data—the kind you find in spreadsheets or databases.\n\nAnd don’t worry—this isn’t just about working with numbers. It’s about answering real-world questions, solving problems, and making decisions based on insights you uncover.\n\nBy the end of this course, you’ll have the skills to transform data into knowledge.\n\nLet’s talk about the tools you need to work with data.\n\nYou might be tempted by low-code or no-code solutions—those point-and-click interfaces that make everything seem so easy. And sure, they’re great for quick wins. But when it comes to serious data analysis, they have some big limitations.\n\nHere’s the thing: data analysis isn’t just about getting answers—it’s about getting credible answers.\n\nTo trust your insights, you need to leave a trail. Think about it—during analysis, you make dozens of tiny decisions:\n\n- Which part of the data should you focus on?\n- What variables should you use?\n- Which patterns caught your eye?\n\nEvery decision shapes your results. And if you—or anyone else—can’t retrace those steps, how can you be sure your conclusions hold up?\n\nThat’s why scripting your analysis is so important.\n\nWith a script, every step is recorded. You can spot mistakes, refine your work, or pick up right where you left off—even months later. Low-code tools? They don’t give you that kind of transparency.\n\nSo, what’s the best language for scripting your data analysis?\n\nThe answer is Python.\n\nPython is the world’s most popular programming language, and for good reason. Created in 1990 by Guido van Rossum, Python has become the go-to language for everything from building websites to powering cutting-edge AI. It may not be the fastest language out there, but it’s arguably the most readable. And in today’s data-driven world, readability matters more than ever. \n\nThe Python ecosystem for data analysis is enormous. Whatever your question, there’s a good chance Python has a library—or ten—that can help.\n\nData analysis is unique—it’s less about traditional programming and more about crafting a story with your data. Your code should be clear and intuitive, not just for you, but for anyone who needs to understand your work.\n\nAnd that includes “future you”—because six months from now, you might not even recognize your own analysis without clear documentation!\n\nSo, as we dive into this course, we’ll emphasize simplicity, transparency, and readability. Because great analysis isn’t just about crunching numbers—it’s about telling a story that stands the test of time.\n\nData analysis is evolving.\n\nToday, some of the most cutting-edge tools are built on high-performance programming languages like Rust, Java, or C++. Why? Because these languages are fast—lightning fast. But here’s the best part: you don’t need to write in these languages to enjoy their benefits.\n\nModern tools now separate the user interface from the engine. That means the algorithms working behind the scenes are the same, no matter which scripting language you use.\n\nInitiatives like Apache Arrow go even further—they create standardized data formats, making it easy to move between tools and platforms without losing performance or compatibility.\n\nIn this course, we’re diving into tools built on Rust—one of the fastest, most efficient programming languages out there. Specifically, we’ll use uv for managing packages and environments and polars for data wrangling.\n\nThese tools are not just fast—they’re scalable.\n\nThe examples we’ll explore together are small—easy to follow and understand. But don’t let that fool you. The same tools we use here can scale effortlessly to handle datasets with billions of rows, processed across dozens of parallel machines.\n\nWhat’s even better? The interface doesn’t change.\n\nSo whether you’re working on a personal project, academic research, or a large-scale business application, the skills you gain here will translate directly to the real world.\n\nThe datasets may be small, but the questions and challenges we tackle are universal. By the end of this course, you’ll be equipped to uncover meaningful insights from your own data, no matter its size or complexity.\n\nLet’s get started on this exciting journey into the world of data literacy!\n\n\n## Shell\n\nBefore we dive into the thrilling world of data analysis, let’s pause and talk about something fundamental: your computer. That’s right, the device you’re watching this on is more than just a tool—it’s the backbone of your data analysis journey. Set it up well, and it will help you create reliable, reproducible, and stunning analytic projects.\n\nBut to unlock its full potential, we need to talk about something that might not look exciting at first glance but is incredibly powerful: the command line—also known as the shell or terminal.\n\nEvery operating system has some version of a terminal. Whether you're on Windows, macOS, or Linux, this is your gateway to greater control over your computer. In the terminal, you don’t rely on menus, buttons, or icons. Instead, you type commands, giving you direct access to your system's capabilities.\n\nNow, if this is new to you, don’t worry! Below this video, you’ll find instructions on how to locate and open the terminal on your operating system. Take a moment to familiarize yourself with launching it, and then meet me back here.\n\nOnce you’re ready, we’ll discuss folders—yes, the simple yet crucial task of organizing your files. If you already know how to navigate your operating system, create new folders, and understand the user directory, feel free to skip ahead to the next video. Otherwise, stick with me, and I’ll walk you through everything you need to know.\n\n:::{.challenge}\nFind and open the terminal on your computer. Take that first step toward becoming a power user!\n:::\n\n## On files and folders\n\nNow that you’ve found your terminal, it’s time to talk about something fundamental to every data analysis project: files and folders.\n\nThink about how your computer organizes everything you create or download—whether it’s a Word document, an Excel spreadsheet, or a photo. These files are stored in folders, and if you’ve ever saved something important, you know how critical it is to remember where it’s located.\n\nWhen working with data analysis, you’ll generate a lot of files—scripts, datasets, reports, visualizations—the list goes on. Keeping all of these files organized and in one place is essential to staying productive. You don’t want to waste time hunting through your computer every time you need something.\n\nHere’s the good news: your operating system already provides a great tool for organizing files—folders. Folders are like containers, and they can even hold other folders. Picture this as a tree, with your main folder as the trunk and subfolders branching out.\n\nLet’s take a moment to explore this on your computer.\n\n- On Windows, you can open File Explorer by clicking the icon on your taskbar or pressing the Windows key + E. Once it’s open, you’ll see something like this:\n\n![](img/win_explorer.png)\n\n- On Mac, you’ll use an app called Finder. Just click its icon in the Dock, and you’ll see a view like this:\n\n![](img/mac_finder.png)\n\n- On Linux, it’s often just called Files, and the interface may vary depending on your distribution. On my Ubuntu setup, it looks like this:\n\n![](img/linux-files.png)\n\nInside these interfaces, folders are easy to spot with their distinct icons. Click on one, and you’ll dive inside to see its contents—maybe more files, maybe more folders.\n\nNow, every operating system has a home base for your personal files. This is typically called your Home folder and contains directories like Music, Pictures, Videos, and Downloads. A special folder called Desktop displays its contents right on your screen.\n\nWhile it’s tempting to store everything on your Desktop for easy access, this isn’t the best long-term solution. A cluttered Desktop can make it harder to stay organized, and let’s be honest—it doesn’t look great either.\n\n![](img/desktop.jpeg)\n\nInstead, consider creating a dedicated folder for your data analysis projects. For example, you could use your Documents folder or create a new folder called Projects. If your Documents folder is synced to the cloud—like with OneDrive or iCloud—think carefully about whether that’s the right place for large datasets. Cloud storage is precious, and you might want to save that space for smaller files like presentations or text documents.\n\nDon’t worry about backups just yet—we’ll cover that later when we dive into version control using Git and GitHub. For now, focus on picking a location that’s tidy, accessible, and works for you.\n\nOnce you’ve chosen your perfect home base, we’ll move on to the next step: learning how to navigate your files and folders using the command line. Trust me, it’s easier than it sounds, and it will make your workflow so much more efficient!\n\n\n## Installing uv\n\n:::{.callout-tip}\n### Objective\nInstall uv.\n:::\n\nWheres my terminal\n\n\nWe will install the main tool. Open the terminal and run\n\n```\n# On macOS and Linux.\n$ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows.\n$ powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nAlternative attempts to deal with installation problems\n\nIf you have python and pip install using pip (you will never need it again)\n\n```\n# With pip.\n$ pip install uv\n```\n\nOn Mac it can be built with Homebrew\n\n```\n# using Homebrew on Mac\n$ brew install uv\n```\n\n::: {.callout-note}\nBefore you proceed, please check that installation is successful by running `uv` in the terminal. You should see something like this\n\n```\nuv\n\n#> An extremely fast Python package manager.\n#>\n#> Usage: uv [OPTIONS] <COMMAND>\n#> \n#> Commands:\n#>  run      Run a command or script\n#>  init     Create a new project\n#>  ...\n```\n\n:::\n\n## Managing python installation\n\n:::{.callout-tip}\n### Objective\nInstall Python using uv\n:::\n\n`uv` is not only powerful package and environment manager, but it also can help manage Python installations. Run the following to see if `uv` can detect an existing Python installation in your system.\n\n```\n$ uv python find\n#> /path/to/your/installation/of/bin/python3\n```\nIf no path is returned you can easily install `uv`-managed latest version of Python with\n\n```\n$ uv python install\n```\n\n\nNavigating to project location using command line (ls, cd and cd ..).\n\n## Projects\n\n:::{.callout-tip}\n### Objective\nCreate project. \n:::\n\nEach of your data analysis endeavours should be stored in a separate project folder. \n\n```\n$ uv init data-literacy-project\ncd data-literacy-project\n```\n\nor alternatively\n\n```\n$ mkdir data-literacy-project\n$ cd data-literacy-project\n$ uv init\n```\n\n## Libraries\n\n:::{.callout-tip}\n### Objective\nAdd dependencies\n:::\n\nWe will need a few libraries. Lets add them \n\n```\n$ uv add gapminder plotnine polars jupyter great_tables setuptools ipykernel pyyaml nbformat nbclient\n```\nIf you did these steps then you should have a file `data-literacy-project/pyproject.toml` which looks something like this\n\n```yaml\n[project]\nname = \"data-literacy-project\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"gapminder>=0.1\",\n    \"ipykernel>=6.29.5\",\n    \"jupyter>=1.1.1\",\n    \"plotnine>=0.13.6\",\n    \"polars>=1.8.2\",\n    \"setuptools>=75.1.0\",\n]\n```\n\n## Activation\n\nFinally we need to activate the environment we created\n\n```\nsource .venv/bin/activate\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"brand":{"brand":{"meta":{"name":"Lund Univerisy brand","link":"https://www.medarbetarwebben.lu.se/grafiskprofil"},"color":{"palette":{"lu-blue":"#000080","lu-gold":"#9C6114","bg-pink":"#E9C4C7","bg-pink-50":"#E9C4C780","bg-blue":"#B9D3DC","bg-blue-50":"#B9D3DC80","bg-green":"#ADCAB8","bg-green-50":"#ADCAB880","bg-beige":"#D6D2C4","bg-beige-50":"#D6D2C480","bg-grey":"#BFB8AF","bg-grey-50":"#BFB8AF80"},"background":"#ffffff","foreground":"#4d4c44","primary":"lu-gold","secondary":"#4d4c44","tertiary":"bg-grey","light":"white"},"logo":{"medium":"LU_logo.png"},"typography":{"fonts":[{"family":"EB Garamond","source":"google"},{"family":"Roboto","source":"google"},{"family":"Fira Code","source":"google"}],"base":"Roboto","headings":{"family":"EB Garamond","color":"lu-gold"},"monospace":"Fira Code"},"defaults":{"bootstrap":{"enable-rounded":false,"navbar-fg":"lu-gold"}}},"data":{"meta":{"name":"Lund Univerisy brand","link":"https://www.medarbetarwebben.lu.se/grafiskprofil"},"color":{"palette":{"lu-blue":"#000080","lu-gold":"#9C6114","bg-pink":"#E9C4C7","bg-pink-50":"#E9C4C780","bg-blue":"#B9D3DC","bg-blue-50":"#B9D3DC80","bg-green":"#ADCAB8","bg-green-50":"#ADCAB880","bg-beige":"#D6D2C4","bg-beige-50":"#D6D2C480","bg-grey":"#BFB8AF","bg-grey-50":"#BFB8AF80"},"background":"#ffffff","foreground":"#4d4c44","primary":"lu-gold","secondary":"#4d4c44","tertiary":"bg-grey","light":"white"},"logo":{"medium":"LU_logo.png"},"typography":{"fonts":[{"family":"EB Garamond","source":"google"},{"family":"Roboto","source":"google"},{"family":"Fira Code","source":"google"}],"base":"Roboto","headings":{"family":"EB Garamond","color":"lu-gold"},"monospace":"Fira Code"},"defaults":{"bootstrap":{"enable-rounded":false,"navbar-fg":"lu-gold"}}},"brandDir":"/home/dm0737pe/Projects/DATA24WEB/brand","projectDir":"/home/dm0737pe/Projects/DATA24WEB","processedData":{"color":{"lu-blue":"#000080","lu-gold":"#9C6114","bg-pink":"#E9C4C7","bg-pink-50":"#E9C4C780","bg-blue":"#B9D3DC","bg-blue-50":"#B9D3DC80","bg-green":"#ADCAB8","bg-green-50":"#ADCAB880","bg-beige":"#D6D2C4","bg-beige-50":"#D6D2C480","bg-grey":"#BFB8AF","bg-grey-50":"#BFB8AF80","background":"#ffffff","foreground":"#4d4c44","primary":"#9C6114","secondary":"#4d4c44","tertiary":"#BFB8AF","light":"white"},"typography":{"base":"Roboto","headings":{"family":"EB Garamond","color":"lu-gold"},"monospace":{"family":"Fira Code"},"monospace-inline":{"family":"Fira Code"},"monospace-block":{"family":"Fira Code"}},"logo":{"images":{},"medium":{"light":{"path":"LU_logo.png"},"dark":{"path":"LU_logo.png"}}}}}},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["custom-callout"],"email-obfuscation":"javascript","toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.37","brand":"brand/_brand.yml","custom-callout":{"challenge":{"icon-symbol":"🛠️","color":"firebrick"},"question":{"icon-symbol":"🧠","color":"pink"}},"page-layout":"full","grid":{"body-width":"1000px"},"theme":["zephyr","brand"],"anchor-sections":true,"title":"Data Literacy with Python"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}